2025-04-05 18:08:41,762 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmphsvqcji3/microservices-demo.yaml
2025-04-05 18:09:42,107 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpfh9u04k1/microservices-demo.yaml
2025-04-05 18:09:42,118 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/frontend -> aegis-demo/backend-service: nodes aegis-demo/backend-service do not exist
2025-04-05 18:09:42,118 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/backend -> aegis-demo/database-service: nodes aegis-demo/database-service do not exist
2025-04-05 18:09:42,119 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/backend -> aegis-demo/cache-service: nodes aegis-demo/cache-service do not exist
2025-04-05 18:09:42,119 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/backend -> aegis-demo/queue-service: nodes aegis-demo/queue-service do not exist
2025-04-05 18:09:42,119 - __main__ - INFO - Built service graph with 11 nodes and 5 edges
2025-04-05 18:09:42,119 - __main__ - INFO - Enabling ML capabilities
2025-04-05 18:09:42,119 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 18:09:42,119 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 18:09:42,119 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 18:09:42,119 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 18:09:42,119 - __main__ - INFO - Loading ML models from models
2025-04-05 18:09:42,121 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 18:09:42,121 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 18:09:42,121 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 18:09:42,121 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 18:09:42,121 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 18:09:42,122 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 18:09:42,124 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 18:09:42,124 - __main__ - INFO - Started ML monitoring
2025-04-05 18:09:42,124 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 18:09:42,134 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:09:42,134 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:09:42,134 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:09:42,544 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 18:10:12,126 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181012 affecting service aegis-demo/queue-service
2025-04-05 18:10:12,128 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 18:10:12,129 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 18:10:42,133 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181042 affecting service aegis-demo/backend
2025-04-05 18:10:42,133 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 18:10:42,133 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 18:10:42,172 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:10:42,173 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:10:42,173 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:11:12,134 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181112 affecting service aegis-demo/frontend-service
2025-04-05 18:11:12,137 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 18:11:12,137 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 18:11:42,142 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181142 affecting service aegis-demo/backend
2025-04-05 18:11:42,144 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 18:11:42,144 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 18:11:42,215 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:11:42,215 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:11:42,215 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:12:12,147 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181212 affecting service aegis-demo/database
2025-04-05 18:12:12,148 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to critical
2025-04-05 18:12:12,149 - __main__ - INFO - Updated health status of aegis-demo/database to critical
2025-04-05 18:12:42,150 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181242 affecting service aegis-demo/frontend-service
2025-04-05 18:12:42,151 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 18:12:42,151 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 18:12:42,240 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:12:42,240 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:12:42,240 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:12:54,664 - __main__ - INFO - Server interrupted by user
2025-04-05 18:12:59,666 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 18:12:59,666 - __main__ - INFO - Stopped ML monitoring
2025-04-05 18:12:59,666 - __main__ - INFO - Server stopped
2025-04-05 18:13:02,273 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpqcv424eg/microservices-demo.yaml
2025-04-05 18:13:02,283 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/frontend -> aegis-demo/backend-service: nodes aegis-demo/backend-service do not exist
2025-04-05 18:13:02,284 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/backend -> aegis-demo/database-service: nodes aegis-demo/database-service do not exist
2025-04-05 18:13:02,284 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/backend -> aegis-demo/cache-service: nodes aegis-demo/cache-service do not exist
2025-04-05 18:13:02,284 - src.graph.service_graph.ServiceGraph - WARNING - Cannot add edge aegis-demo/backend -> aegis-demo/queue-service: nodes aegis-demo/queue-service do not exist
2025-04-05 18:13:02,284 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 18:13:02,284 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 18:13:02,284 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-05 18:13:02,284 - __main__ - INFO - Enabling ML capabilities
2025-04-05 18:13:02,284 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 18:13:02,284 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 18:13:02,284 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 18:13:02,284 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 18:13:02,284 - __main__ - INFO - Loading ML models from models
2025-04-05 18:13:02,286 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 18:13:02,286 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 18:13:02,286 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 18:13:02,287 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 18:13:02,287 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 18:13:02,287 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 18:13:02,288 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 18:13:02,296 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:13:02,296 - __main__ - INFO - Started ML monitoring
2025-04-05 18:13:02,296 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:13:02,297 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 18:13:02,297 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:13:02,431 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 18:13:32,305 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181332 affecting service default/aegis-demo
2025-04-05 18:13:32,306 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 18:13:32,306 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 18:14:02,331 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181402 affecting service aegis-demo/frontend
2025-04-05 18:14:02,342 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:14:02,342 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to critical
2025-04-05 18:14:02,342 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:14:02,342 - __main__ - INFO - Updated health status of aegis-demo/frontend to critical
2025-04-05 18:14:02,342 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:14:32,345 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405181432 affecting service aegis-demo/backend-service
2025-04-05 18:14:32,347 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 18:14:32,347 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 18:14:32,974 - __main__ - INFO - Server interrupted by user
2025-04-05 18:14:37,977 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 18:14:37,978 - __main__ - INFO - Stopped ML monitoring
2025-04-05 18:14:37,978 - __main__ - INFO - Server stopped
2025-04-05 18:17:06,713 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpe1drbekw/microservices-demo.yaml
2025-04-05 18:17:06,725 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 18:17:06,725 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 18:17:06,725 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-05 18:17:06,725 - __main__ - INFO - Enabling ML capabilities
2025-04-05 18:17:06,725 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 18:17:06,725 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 18:17:06,725 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 18:17:06,725 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 18:17:06,725 - __main__ - INFO - Loading ML models from models
2025-04-05 18:17:06,728 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 18:17:06,728 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 18:17:06,728 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 18:17:06,728 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 18:17:06,728 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 18:17:06,729 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 18:17:06,731 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 18:17:06,732 - __main__ - INFO - Started ML monitoring
2025-04-05 18:17:06,732 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 18:17:06,747 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:17:06,747 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:17:06,747 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:17:06,997 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 18:17:26,393 - __main__ - INFO - Server interrupted by user
2025-04-05 18:17:31,399 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 18:17:31,400 - __main__ - INFO - Stopped ML monitoring
2025-04-05 18:17:31,400 - __main__ - INFO - Server stopped
2025-04-05 18:47:34,748 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpjfy8ik1t/microservices-demo.yaml
2025-04-05 18:47:34,759 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 18:47:34,759 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 18:47:34,759 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-05 18:47:34,759 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 18:47:34,771 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 18:47:34,771 - __main__ - INFO - Enabling ML capabilities
2025-04-05 18:47:34,771 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 18:47:34,771 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 18:47:34,771 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 18:47:34,771 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 18:47:34,771 - __main__ - INFO - Loading ML models from models
2025-04-05 18:47:34,774 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 18:47:34,774 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 18:47:34,774 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 18:47:34,774 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 18:47:34,774 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 18:47:34,775 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 18:47:34,776 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 18:47:34,776 - __main__ - INFO - Started ML monitoring
2025-04-05 18:47:34,776 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 18:47:34,786 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:47:34,786 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:47:34,787 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:47:35,041 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 18:48:04,777 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405184804 affecting service aegis-demo/cache-service
2025-04-05 18:48:04,778 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 18:48:04,778 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 18:48:34,779 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405184834 affecting service aegis-demo/queue-service
2025-04-05 18:48:34,780 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 18:48:34,780 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 18:48:34,817 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:48:34,817 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:48:34,817 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:49:04,781 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405184904 affecting service aegis-demo/cache
2025-04-05 18:49:04,781 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to critical
2025-04-05 18:49:04,781 - __main__ - INFO - Updated health status of aegis-demo/cache to critical
2025-04-05 18:49:34,783 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405184934 affecting service default/aegis-demo
2025-04-05 18:49:34,783 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 18:49:34,784 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 18:49:34,843 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:49:34,843 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:49:34,843 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:50:04,785 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185004 affecting service default/aegis-demo
2025-04-05 18:50:04,787 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 18:50:04,787 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 18:50:34,793 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185034 affecting service aegis-demo/frontend-service
2025-04-05 18:50:34,794 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 18:50:34,794 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 18:50:34,881 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:50:34,881 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:50:34,881 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:51:04,800 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185104 affecting service aegis-demo/queue-service
2025-04-05 18:51:04,801 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 18:51:04,801 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 18:51:34,806 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185134 affecting service default/aegis-demo
2025-04-05 18:51:34,807 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 18:51:34,808 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 18:51:34,915 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:51:34,916 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:51:34,916 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:52:04,811 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185204 affecting service aegis-demo/cache
2025-04-05 18:52:04,813 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to critical
2025-04-05 18:52:04,813 - __main__ - INFO - Updated health status of aegis-demo/cache to critical
2025-04-05 18:52:34,817 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185234 affecting service aegis-demo/queue-service
2025-04-05 18:52:34,818 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 18:52:34,818 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 18:52:34,940 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:52:34,940 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:52:34,940 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:53:04,823 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185304 affecting service aegis-demo/database-service
2025-04-05 18:53:04,823 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to critical
2025-04-05 18:53:04,823 - __main__ - INFO - Updated health status of aegis-demo/database-service to critical
2025-04-05 18:53:34,828 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185334 affecting service aegis-demo/backend-service
2025-04-05 18:53:34,829 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 18:53:34,829 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 18:53:34,970 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:53:34,970 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:53:34,970 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:54:04,834 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185404 affecting service aegis-demo/backend-service
2025-04-05 18:54:04,837 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 18:54:04,837 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 18:54:34,839 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185434 affecting service default/aegis-demo
2025-04-05 18:54:34,841 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 18:54:34,841 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 18:54:35,004 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:54:35,005 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:54:35,005 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:55:04,843 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185504 affecting service aegis-demo/backend-service
2025-04-05 18:55:04,843 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 18:55:04,844 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 18:55:34,854 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185534 affecting service aegis-demo/cache-service
2025-04-05 18:55:34,856 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 18:55:34,856 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 18:55:35,034 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:55:35,034 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:55:35,034 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:56:04,861 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185604 affecting service aegis-demo/cache
2025-04-05 18:56:04,861 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to critical
2025-04-05 18:56:04,862 - __main__ - INFO - Updated health status of aegis-demo/cache to critical
2025-04-05 18:56:34,872 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185634 affecting service default/aegis-demo
2025-04-05 18:56:34,874 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 18:56:34,874 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 18:56:35,081 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:56:35,081 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:56:35,081 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:57:04,883 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185704 affecting service aegis-demo/backend
2025-04-05 18:57:04,884 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 18:57:04,884 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 18:57:34,889 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185734 affecting service aegis-demo/backend
2025-04-05 18:57:34,890 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 18:57:34,890 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 18:57:35,128 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:57:35,128 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:57:35,128 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:58:04,891 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185804 affecting service aegis-demo/backend-service
2025-04-05 18:58:04,892 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 18:58:04,892 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 18:58:34,896 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185834 affecting service aegis-demo/frontend-service
2025-04-05 18:58:34,897 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 18:58:34,897 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 18:58:35,159 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:58:35,159 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:58:35,159 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 18:59:04,898 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185904 affecting service aegis-demo/backend-service
2025-04-05 18:59:04,899 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 18:59:04,899 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 18:59:34,903 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405185934 affecting service aegis-demo/backend
2025-04-05 18:59:34,904 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 18:59:34,904 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 18:59:35,191 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 18:59:35,191 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 18:59:35,191 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:00:04,907 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190004 affecting service aegis-demo/backend
2025-04-05 19:00:04,908 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 19:00:04,908 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 19:00:34,912 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190034 affecting service aegis-demo/cache-service
2025-04-05 19:00:34,914 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:00:34,914 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:00:35,237 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:00:35,237 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:00:35,237 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:01:04,915 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190104 affecting service aegis-demo/cache-service
2025-04-05 19:01:04,917 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:01:04,917 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:01:34,922 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190134 affecting service aegis-demo/queue
2025-04-05 19:01:34,925 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to critical
2025-04-05 19:01:34,925 - __main__ - INFO - Updated health status of aegis-demo/queue to critical
2025-04-05 19:01:35,267 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:01:35,267 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:01:35,267 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:02:04,930 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190204 affecting service aegis-demo/queue-service
2025-04-05 19:02:04,932 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 19:02:04,932 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 19:02:12,021 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmp0z4js63t/microservices-demo.yaml
2025-04-05 19:02:12,032 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:02:12,032 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:02:12,034 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:02:12,034 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:02:12,034 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:02:12,035 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:02:12,035 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:02:12,035 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:02:12,035 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:02:12,035 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:02:12,035 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:02:12,035 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:02:12,035 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:02:12,035 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:02:12,035 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:02:12,042 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:02:12,042 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:02:12,042 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:02:12,042 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:02:12,042 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:02:12,042 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:02:12,042 - __main__ - INFO - Loading ML models from models
2025-04-05 19:02:12,044 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:02:12,044 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:02:12,044 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:02:12,044 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:02:12,044 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:02:12,045 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:02:12,045 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:02:12,045 - __main__ - INFO - Started ML monitoring
2025-04-05 19:02:12,045 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:02:12,052 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:02:12,052 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:02:12,053 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:02:23,257 - __main__ - INFO - Server interrupted by user
2025-04-05 19:02:28,263 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:02:28,263 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:02:28,264 - __main__ - INFO - Stopped metrics monitoring
2025-04-05 19:02:28,264 - __main__ - INFO - Server stopped
2025-04-05 19:03:29,929 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpuzfbpxbk/microservices-demo.yaml
2025-04-05 19:03:29,941 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:03:29,941 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:03:29,942 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:03:29,942 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:03:29,942 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:03:29,942 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:03:29,943 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:03:29,943 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:03:29,943 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:03:29,943 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:03:29,943 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:03:29,943 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:03:29,943 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:03:29,943 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:03:29,943 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:03:29,950 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:03:29,950 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:03:29,950 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:03:29,950 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:03:29,950 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:03:29,950 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:03:29,950 - __main__ - INFO - Loading ML models from models
2025-04-05 19:03:29,952 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:03:29,952 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:03:29,952 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:03:29,953 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:03:29,953 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:03:29,953 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:03:29,955 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:03:29,955 - __main__ - INFO - Started ML monitoring
2025-04-05 19:03:29,955 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:03:29,964 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:03:29,964 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:03:29,964 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:03:30,222 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:03:59,968 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190359 affecting service aegis-demo/backend
2025-04-05 19:03:59,972 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 19:03:59,972 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 19:04:29,982 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190429 affecting service aegis-demo/backend-service
2025-04-05 19:04:29,983 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 19:04:29,984 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 19:04:30,012 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:04:30,012 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:04:30,013 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:04:59,991 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190459 affecting service aegis-demo/frontend-service
2025-04-05 19:04:59,993 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:04:59,993 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:05:30,045 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190530 affecting service aegis-demo/frontend-service
2025-04-05 19:05:30,208 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:05:30,208 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:05:30,354 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:05:30,354 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:05:30,354 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:06:00,214 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190600 affecting service aegis-demo/database
2025-04-05 19:06:00,216 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to critical
2025-04-05 19:06:00,216 - __main__ - INFO - Updated health status of aegis-demo/database to critical
2025-04-05 19:06:30,222 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190630 affecting service aegis-demo/frontend-service
2025-04-05 19:06:30,223 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:06:30,223 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:06:30,415 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:06:30,415 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:06:30,415 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:07:00,227 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190700 affecting service aegis-demo/queue-service
2025-04-05 19:07:00,229 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 19:07:00,230 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 19:07:30,233 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190730 affecting service aegis-demo/database-service
2025-04-05 19:07:30,234 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to critical
2025-04-05 19:07:30,235 - __main__ - INFO - Updated health status of aegis-demo/database-service to critical
2025-04-05 19:07:30,438 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:07:30,438 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:07:30,438 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:08:00,237 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190800 affecting service aegis-demo/frontend-service
2025-04-05 19:08:00,241 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:08:00,242 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:08:30,261 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190830 affecting service aegis-demo/backend
2025-04-05 19:08:30,278 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 19:08:30,279 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 19:08:30,476 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:08:30,476 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:08:30,476 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:09:00,286 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190900 affecting service aegis-demo/queue
2025-04-05 19:09:00,289 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to critical
2025-04-05 19:09:00,289 - __main__ - INFO - Updated health status of aegis-demo/queue to critical
2025-04-05 19:09:30,294 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405190930 affecting service aegis-demo/backend-service
2025-04-05 19:09:30,294 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 19:09:30,294 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 19:09:30,498 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:09:30,498 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:09:30,498 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:10:00,301 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191000 affecting service aegis-demo/cache-service
2025-04-05 19:10:00,304 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:10:00,304 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:10:30,306 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191030 affecting service default/aegis-demo
2025-04-05 19:10:30,308 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 19:10:30,308 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 19:10:30,535 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:10:30,535 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:10:30,535 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:11:00,313 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191100 affecting service aegis-demo/queue
2025-04-05 19:11:00,314 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to critical
2025-04-05 19:11:00,315 - __main__ - INFO - Updated health status of aegis-demo/queue to critical
2025-04-05 19:11:30,318 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191130 affecting service aegis-demo/database
2025-04-05 19:11:30,320 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to critical
2025-04-05 19:11:30,320 - __main__ - INFO - Updated health status of aegis-demo/database to critical
2025-04-05 19:11:30,575 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:11:30,576 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:11:30,576 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:12:00,325 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191200 affecting service aegis-demo/cache-service
2025-04-05 19:12:00,327 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:12:00,327 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:12:30,331 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191230 affecting service aegis-demo/queue-service
2025-04-05 19:12:30,334 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 19:12:30,338 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 19:12:30,607 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:12:30,607 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:12:30,607 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:13:00,342 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191300 affecting service aegis-demo/queue
2025-04-05 19:13:00,344 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to critical
2025-04-05 19:13:00,344 - __main__ - INFO - Updated health status of aegis-demo/queue to critical
2025-04-05 19:13:30,349 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191330 affecting service aegis-demo/cache-service
2025-04-05 19:13:30,351 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:13:30,351 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:13:30,724 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:13:30,724 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:13:30,724 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:14:00,358 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191400 affecting service aegis-demo/cache
2025-04-05 19:14:00,360 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to critical
2025-04-05 19:14:00,360 - __main__ - INFO - Updated health status of aegis-demo/cache to critical
2025-04-05 19:14:30,372 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191430 affecting service aegis-demo/frontend
2025-04-05 19:14:30,376 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to critical
2025-04-05 19:14:30,376 - __main__ - INFO - Updated health status of aegis-demo/frontend to critical
2025-04-05 19:14:30,762 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:14:30,762 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:14:30,762 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:15:00,383 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191500 affecting service aegis-demo/cache
2025-04-05 19:15:00,385 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to critical
2025-04-05 19:15:00,385 - __main__ - INFO - Updated health status of aegis-demo/cache to critical
2025-04-05 19:15:30,387 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191530 affecting service aegis-demo/frontend-service
2025-04-05 19:15:30,394 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:15:30,396 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:15:30,802 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:15:30,802 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:15:30,802 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:16:00,450 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191600 affecting service aegis-demo/backend
2025-04-05 19:16:00,479 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 19:16:00,482 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 19:16:14,497 - __main__ - INFO - Server interrupted by user
2025-04-05 19:16:19,503 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:16:19,503 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:16:19,503 - __main__ - INFO - Stopped metrics monitoring
2025-04-05 19:16:19,503 - __main__ - INFO - Server stopped
2025-04-05 19:16:25,556 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpya_394n5/microservices-demo.yaml
2025-04-05 19:16:25,567 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:16:25,567 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:16:25,568 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:16:25,568 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:16:25,568 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:16:25,568 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:16:25,569 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:16:25,569 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:16:25,569 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:16:25,569 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:16:25,569 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:16:25,569 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:16:25,569 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:16:25,569 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:16:25,569 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:16:25,575 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:16:25,575 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:16:25,575 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:16:25,575 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:16:25,575 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:16:25,575 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:16:25,576 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:16:25,576 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:16:25,576 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:16:25,576 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:16:25,576 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:16:25,576 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:16:25,576 - __main__ - INFO - Loading ML models from models
2025-04-05 19:16:25,578 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:16:25,578 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:16:25,578 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:16:25,578 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:16:25,578 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:16:25,578 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:16:25,581 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:16:25,586 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:16:25,586 - __main__ - INFO - Started ML monitoring
2025-04-05 19:16:25,586 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:16:25,586 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:16:25,586 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:16:25,880 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:16:55,592 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405191655 affecting service aegis-demo/backend
2025-04-05 19:16:55,592 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-05 19:16:55,592 - __main__ - INFO - Updated health status of aegis-demo/backend to critical
2025-04-05 19:16:58,852 - __main__ - INFO - Server interrupted by user
2025-04-05 19:17:03,858 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:17:03,862 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:17:03,864 - __main__ - INFO - Stopped metrics monitoring
2025-04-05 19:17:03,864 - __main__ - INFO - Server stopped
2025-04-05 19:21:34,539 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpf44uhraq/microservices-demo.yaml
2025-04-05 19:21:34,551 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:21:34,551 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:21:34,552 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:21:34,552 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:21:34,552 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:21:34,552 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:21:34,553 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:21:34,553 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:21:34,553 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:21:34,553 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:21:34,553 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:21:34,553 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:21:34,553 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:21:34,553 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:21:34,553 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:21:34,560 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:21:34,561 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:21:34,561 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:21:34,561 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:21:34,561 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:21:34,561 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:21:34,561 - __main__ - INFO - Loading ML models from models
2025-04-05 19:21:34,563 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:21:34,563 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:21:34,563 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:21:34,564 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:21:34,564 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:21:34,564 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:21:34,566 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:21:34,566 - __main__ - INFO - Started ML monitoring
2025-04-05 19:21:34,566 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:21:34,576 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:21:34,576 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:21:34,576 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:21:34,748 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:21:52,935 - __main__ - INFO - Server interrupted by user
2025-04-05 19:21:57,938 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:21:57,939 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:21:57,939 - __main__ - INFO - Stopped metrics monitoring
2025-04-05 19:21:57,939 - __main__ - INFO - Server stopped
2025-04-05 19:27:45,818 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpt6df_39o/microservices-demo.yaml
2025-04-05 19:27:45,829 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:27:45,829 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:27:45,830 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:27:45,830 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:27:45,830 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:27:45,830 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:27:45,831 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:27:45,831 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:27:45,831 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:27:45,831 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:27:45,831 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:27:45,831 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:27:45,831 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:27:45,831 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:27:45,831 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:27:45,838 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:27:45,838 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:27:45,838 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:27:45,838 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:27:45,838 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:27:45,838 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:27:45,838 - __main__ - INFO - Loading ML models from models
2025-04-05 19:27:45,841 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:27:45,841 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:27:45,841 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:27:45,841 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:27:45,841 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:27:45,841 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:27:45,843 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:27:45,843 - __main__ - INFO - Started ML monitoring
2025-04-05 19:27:45,843 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:27:45,857 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:27:45,857 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:27:45,857 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:27:45,984 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:28:15,853 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405192815 affecting service aegis-demo/cache-service
2025-04-05 19:28:15,857 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:28:15,857 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:28:45,860 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405192845 affecting service default/aegis-demo
2025-04-05 19:28:45,866 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 19:28:45,868 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 19:28:45,890 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:28:45,890 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:28:45,890 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:29:15,869 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405192915 affecting service aegis-demo/cache-service
2025-04-05 19:29:15,871 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:29:15,871 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:29:45,878 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405192945 affecting service aegis-demo/database-service
2025-04-05 19:29:45,881 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to critical
2025-04-05 19:29:45,882 - __main__ - INFO - Updated health status of aegis-demo/database-service to critical
2025-04-05 19:29:46,033 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:29:46,033 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:29:46,033 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:30:15,883 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405193015 affecting service aegis-demo/database-service
2025-04-05 19:30:15,884 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to critical
2025-04-05 19:30:15,884 - __main__ - INFO - Updated health status of aegis-demo/database-service to critical
2025-04-05 19:39:16,379 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmptmumcdxe/microservices-demo.yaml
2025-04-05 19:39:16,390 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:39:16,391 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:39:16,391 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-05 19:39:16,706 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:39:56,040 - __main__ - INFO - Server interrupted by user
2025-04-05 19:39:56,042 - __main__ - INFO - Server stopped
2025-04-05 19:45:10,289 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpo4u90sct/microservices-demo.yaml
2025-04-05 19:45:10,300 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:45:10,300 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:45:10,300 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-05 19:45:10,448 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:45:41,329 - __main__ - INFO - Server interrupted by user
2025-04-05 19:45:41,330 - __main__ - INFO - Server stopped
2025-04-05 19:46:08,179 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpt555em57/microservices-demo.yaml
2025-04-05 19:46:08,190 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:46:08,190 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:46:08,192 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:46:08,192 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:46:08,192 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:46:08,192 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:46:08,193 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:46:08,193 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:46:08,193 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:46:08,193 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:46:08,193 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:46:08,193 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:46:08,193 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:46:08,193 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:46:08,199 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:46:08,199 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:46:08,199 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:46:08,200 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:46:08,200 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:46:08,200 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:46:08,200 - __main__ - INFO - Loading ML models from models
2025-04-05 19:46:08,202 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:46:08,202 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:46:08,202 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:46:08,202 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:46:08,202 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:46:08,203 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:46:08,204 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:46:08,204 - __main__ - INFO - Started ML monitoring
2025-04-05 19:46:08,204 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:46:08,215 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:46:08,215 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:46:08,215 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:46:08,345 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:46:38,209 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194638 affecting service aegis-demo/cache
2025-04-05 19:46:38,210 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to critical
2025-04-05 19:46:38,210 - __main__ - INFO - Updated health status of aegis-demo/cache to critical
2025-04-05 19:47:08,211 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194708 affecting service default/aegis-demo
2025-04-05 19:47:08,213 - src.graph.service_graph.ServiceGraph - INFO - Updated node default/aegis-demo attribute health_status to critical
2025-04-05 19:47:08,213 - __main__ - INFO - Updated health status of default/aegis-demo to critical
2025-04-05 19:47:08,263 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:47:08,263 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:47:08,263 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:47:38,217 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194738 affecting service aegis-demo/frontend-service
2025-04-05 19:47:38,219 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:47:38,219 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:48:08,224 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194808 affecting service aegis-demo/database
2025-04-05 19:48:08,225 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to critical
2025-04-05 19:48:08,225 - __main__ - INFO - Updated health status of aegis-demo/database to critical
2025-04-05 19:48:08,293 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:48:08,293 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:48:08,293 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:48:38,230 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194838 affecting service aegis-demo/backend-service
2025-04-05 19:48:38,231 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 19:48:38,231 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 19:49:08,232 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194908 affecting service aegis-demo/cache-service
2025-04-05 19:49:08,232 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-05 19:49:08,232 - __main__ - INFO - Updated health status of aegis-demo/cache-service to critical
2025-04-05 19:49:08,322 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:49:08,322 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:49:08,322 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:49:38,237 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405194938 affecting service aegis-demo/backend-service
2025-04-05 19:49:38,238 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 19:49:38,238 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 19:50:08,244 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195008 affecting service aegis-demo/queue-service
2025-04-05 19:50:08,245 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-05 19:50:08,245 - __main__ - INFO - Updated health status of aegis-demo/queue-service to critical
2025-04-05 19:50:08,353 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:50:08,354 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:50:08,354 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:50:38,248 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195038 affecting service aegis-demo/backend-service
2025-04-05 19:50:38,249 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 19:50:38,249 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 19:51:08,257 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195108 affecting service aegis-demo/backend-service
2025-04-05 19:51:08,261 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to critical
2025-04-05 19:51:08,261 - __main__ - INFO - Updated health status of aegis-demo/backend-service to critical
2025-04-05 19:51:08,400 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:51:08,400 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:51:08,400 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:51:38,263 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195138 affecting service aegis-demo/database-service
2025-04-05 19:51:38,265 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to critical
2025-04-05 19:51:38,265 - __main__ - INFO - Updated health status of aegis-demo/database-service to critical
2025-04-05 19:52:08,267 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195208 affecting service aegis-demo/database
2025-04-05 19:52:08,269 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to critical
2025-04-05 19:52:08,270 - __main__ - INFO - Updated health status of aegis-demo/database to critical
2025-04-05 19:52:08,447 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:52:08,447 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:52:08,447 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:52:38,275 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195238 affecting service aegis-demo/frontend-service
2025-04-05 19:52:38,276 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to critical
2025-04-05 19:52:38,276 - __main__ - INFO - Updated health status of aegis-demo/frontend-service to critical
2025-04-05 19:53:08,277 - __main__ - INFO - Injected synthetic issue synthetic-issue-20250405195308 affecting service aegis-demo/queue
2025-04-05 19:53:08,278 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to critical
2025-04-05 19:53:08,279 - __main__ - INFO - Updated health status of aegis-demo/queue to critical
2025-04-05 19:53:08,495 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:53:08,495 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:53:08,495 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:53:11,801 - __main__ - INFO - Server interrupted by user
2025-04-05 19:53:16,803 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:53:16,804 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:53:16,804 - __main__ - INFO - Stopped metrics monitoring
2025-04-05 19:53:16,804 - __main__ - INFO - Server stopped
2025-04-05 19:53:17,791 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpdtash5mo/microservices-demo.yaml
2025-04-05 19:53:17,802 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:53:17,802 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:53:17,803 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:53:17,803 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:53:17,803 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:53:17,804 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:53:17,804 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:53:17,804 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:53:17,804 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:53:17,804 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:53:17,804 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:53:17,804 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:53:17,804 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:53:17,804 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 19:53:17,811 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-05 19:53:17,811 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:53:17,811 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:53:17,811 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:53:17,811 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:53:17,811 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:53:17,811 - __main__ - INFO - Loading ML models from models
2025-04-05 19:53:17,813 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:53:17,813 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:53:17,813 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:53:17,814 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:53:17,814 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:53:17,814 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:53:17,815 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:53:17,822 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:53:17,822 - __main__ - INFO - Started ML monitoring
2025-04-05 19:53:17,822 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:53:17,822 - __main__ - INFO - Scheduled anomaly injection
2025-04-05 19:53:17,822 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:53:18,465 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:53:36,584 - __main__ - INFO - Server interrupted by user
2025-04-05 19:53:36,586 - __main__ - INFO - Stopping anomaly injection thread...
2025-04-05 19:53:36,881 - __main__ - INFO - Anomaly injection thread stopped
2025-04-05 19:53:41,883 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:53:41,884 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:53:41,884 - __main__ - INFO - Stopped metrics monitoring
2025-04-05 19:53:41,884 - __main__ - INFO - Server stopped
2025-04-05 19:54:56,642 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmps2slmx94/microservices-demo.yaml
2025-04-05 19:54:56,654 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:54:56,654 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:54:56,656 - __main__ - INFO - Enhancing service graph with ML-based relationship detection...
2025-04-05 19:54:56,656 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Enhancing service graph with ML...
2025-04-05 19:54:56,656 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Generating service embeddings...
2025-04-05 19:54:56,656 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Detecting relationships from embeddings...
2025-04-05 19:54:56,656 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing traffic patterns...
2025-04-05 19:54:56,657 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing log correlations...
2025-04-05 19:54:56,657 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Analyzing deployment patterns...
2025-04-05 19:54:56,657 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Pruning unlikely relationships...
2025-04-05 19:54:56,657 - src.ml.graph.ml_service_graph.MLServiceGraph - INFO - Service graph enhancement complete
2025-04-05 19:54:56,657 - __main__ - INFO - ML-based graph enhancement complete
2025-04-05 19:54:56,657 - __main__ - INFO - Built service graph with 11 nodes and 60 edges
2025-04-05 19:54:56,657 - __main__ - INFO - Enabling ML capabilities
2025-04-05 19:54:56,657 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: metrics
2025-04-05 19:54:56,657 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: logs
2025-04-05 19:54:56,657 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Added detector: ml
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rules
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Added learner: rl
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Restart Service
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Scale Service
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Rollback Deployment
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Drain Node
2025-04-05 19:54:56,657 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Registered action: Clear Cache
2025-04-05 19:54:56,657 - __main__ - INFO - Loading ML models from models
2025-04-05 19:54:56,660 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error loading model for detector metrics: 'baseline'
2025-04-05 19:54:56,660 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: logs
2025-04-05 19:54:56,660 - src.ml.anomaly_detection.AnomalyDetectionEngine - INFO - Loaded model for detector: ml
2025-04-05 19:54:56,661 - src.ml.learning.remediation_learner.RemediationLearningEngine - ERROR - Error loading model for learner rules: 'list' object has no attribute 'items'
2025-04-05 19:54:56,661 - src.ml.learning.remediation_learner.RemediationLearningEngine - INFO - Loaded model for learner: rl
2025-04-05 19:54:56,662 - src.ml.integration.MLIntegrationEngine - INFO - Loaded all ML models from models
2025-04-05 19:54:56,664 - src.ml.integration.MLIntegrationEngine - INFO - Started monitoring thread
2025-04-05 19:54:56,664 - __main__ - INFO - Started ML monitoring
2025-04-05 19:54:56,675 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector metrics: Model must be trained before detection
2025-04-05 19:54:56,675 - src.ml.anomaly_detection.AnomalyDetectionEngine - ERROR - Error in detector logs: Model must be trained before detection
2025-04-05 19:54:56,675 - src.ml.integration.MLIntegrationEngine - INFO - Detected anomalies: 0
2025-04-05 19:54:56,971 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:55:14,219 - __main__ - INFO - Server interrupted by user
2025-04-05 19:55:19,224 - src.ml.integration.MLIntegrationEngine - INFO - Stopped monitoring thread
2025-04-05 19:55:19,225 - __main__ - INFO - Stopped ML monitoring
2025-04-05 19:55:19,225 - __main__ - INFO - Server stopped
2025-04-05 19:55:38,547 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpa2j8xsdi/microservices-demo.yaml
2025-04-05 19:55:38,560 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 19:55:38,560 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 19:55:38,560 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-05 19:55:38,564 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 19:56:30,171 - __main__ - INFO - Server interrupted by user
2025-04-05 19:56:30,172 - __main__ - INFO - Server stopped
2025-04-05 20:05:16,235 - __main__ - ERROR - Kubernetes client library not installed. Please install it with 'pip install kubernetes'
2025-04-05 20:06:31,422 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-05 20:06:31,493 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpksqmwssv/k8s-resources.yaml
2025-04-05 20:06:31,500 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-05 20:06:31,500 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 20:06:31,500 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 20:06:31,500 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-05 20:06:31,779 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 20:08:13,427 - __main__ - INFO - Server interrupted by user
2025-04-05 20:08:13,442 - __main__ - INFO - Server stopped
2025-04-05 20:20:47,854 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-05 20:20:47,940 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmp9wdkqeim/k8s-resources.yaml
2025-04-05 20:20:47,948 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-05 20:20:47,948 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-05 20:20:47,948 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-05 20:20:47,948 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-05 20:20:47,948 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-05 20:20:47,989 - __main__ - INFO - Successfully connected to Prometheus
2025-04-05 20:20:48,228 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-05 20:20:48,228 - __main__ - INFO - Started metrics monitoring
2025-04-05 20:20:48,352 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-05 20:20:48,414 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:21:48,879 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:22:49,643 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:23:50,164 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:24:50,607 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:25:56,741 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:26:57,215 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:27:57,806 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:29:00,599 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:30:01,595 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:31:02,357 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:32:02,940 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:33:03,526 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:34:04,083 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:35:04,715 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:36:05,318 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:37:08,173 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:38:08,819 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:39:09,520 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:40:10,158 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:41:10,589 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:42:11,055 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:43:11,459 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:44:11,849 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:46:29,255 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:47:40,947 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:48:53,534 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:51:05,199 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 20:57:51,512 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 21:01:30,210 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 21:06:19,047 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 21:10:26,806 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 21:12:39,024 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 21:31:56,893 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 21:54:19,478 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 22:13:35,739 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 22:37:50,195 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 22:38:50,634 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-05 22:39:51,044 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:35:24,747 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 09:35:24,805 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpp5k6uq9y/k8s-resources.yaml
2025-04-06 09:35:24,812 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 09:35:24,812 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 09:35:24,812 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 09:35:24,812 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 09:35:24,812 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 09:35:24,820 - __main__ - ERROR - Could not connect to Prometheus server
2025-04-06 09:35:24,892 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 09:42:58,649 - __main__ - INFO - Server interrupted by user
2025-04-06 09:42:58,651 - __main__ - INFO - Stopped metrics monitoring
2025-04-06 09:42:58,652 - __main__ - INFO - Server stopped
2025-04-06 09:43:03,222 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 09:43:03,276 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpiwufiddq/k8s-resources.yaml
2025-04-06 09:43:03,289 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 09:43:03,290 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 09:43:03,290 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 09:43:03,290 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 09:43:03,290 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 09:43:03,307 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 09:43:03,465 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 09:43:03,466 - __main__ - INFO - Started metrics monitoring
2025-04-06 09:43:03,528 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 09:43:03,812 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:43:32,972 - __main__ - INFO - Server interrupted by user
2025-04-06 09:43:33,910 - src.metrics.metrics_integration.MetricsIntegration - INFO - Stopped metrics monitoring thread
2025-04-06 09:43:33,910 - __main__ - INFO - Stopped metrics monitoring
2025-04-06 09:43:33,911 - __main__ - INFO - Server stopped
2025-04-06 09:52:21,559 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 09:52:21,621 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpmxiq8bf3/k8s-resources.yaml
2025-04-06 09:52:21,628 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 09:52:21,628 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 09:52:21,628 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 09:52:21,628 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 09:52:21,628 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 09:52:21,644 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 09:52:21,936 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 09:52:21,936 - __main__ - INFO - Started metrics monitoring
2025-04-06 09:52:21,998 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 09:52:22,159 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:53:22,517 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:54:22,909 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:55:23,319 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:56:23,693 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:57:24,080 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:58:24,465 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 09:59:24,862 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:06:17,991 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 10:06:18,047 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmp7cqko71p/k8s-resources.yaml
2025-04-06 10:06:18,054 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 10:06:18,054 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 10:06:18,055 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 10:06:18,055 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 10:06:18,055 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 10:06:18,069 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 10:06:18,336 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 10:06:18,336 - __main__ - INFO - Started metrics monitoring
2025-04-06 10:06:18,397 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 10:06:18,576 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:07:18,925 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:08:19,273 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:09:19,658 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:10:20,144 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:11:20,566 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:12:21,091 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:13:21,494 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:14:21,880 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:15:22,261 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:16:22,621 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:17:23,021 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:18:23,380 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:19:23,872 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:20:24,251 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:21:24,670 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:22:25,114 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:23:25,503 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:24:25,857 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:25:26,253 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:26:26,684 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:27:27,077 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:28:27,766 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:29:28,361 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:30:29,165 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:31:48,886 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:33:11,063 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:37:01,374 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:38:08,616 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:39:22,203 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:40:35,024 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:41:54,029 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:43:26,820 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:44:41,219 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:45:54,751 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:47:09,672 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:48:28,802 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:49:49,949 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:51:07,064 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:52:14,651 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:53:48,204 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:56:06,649 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:57:54,527 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 10:58:14,191 - __main__ - INFO - Server interrupted by user
2025-04-06 10:58:14,588 - src.metrics.metrics_integration.MetricsIntegration - INFO - Stopped metrics monitoring thread
2025-04-06 10:58:14,589 - __main__ - INFO - Stopped metrics monitoring
2025-04-06 10:58:14,589 - __main__ - INFO - Server stopped
2025-04-06 10:59:32,400 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 10:59:32,456 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpqxgiumjy/k8s-resources.yaml
2025-04-06 10:59:32,463 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 10:59:32,463 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 10:59:32,463 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 10:59:32,463 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 10:59:32,464 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 10:59:32,478 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 10:59:32,944 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 10:59:32,944 - __main__ - INFO - Started metrics monitoring
2025-04-06 10:59:33,088 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 10:59:33,416 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:00:34,012 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:01:34,601 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:02:35,105 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:02:35,166 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpq1x2ccm7/k8s-resources.yaml
2025-04-06 11:02:35,173 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:02:35,173 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:02:35,173 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:02:35,173 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:02:35,173 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 11:02:35,189 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 11:02:35,189 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:02:35,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:02:35,258 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:02:35,268 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,268 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:02:35,277 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,277 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:02:35,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:02:35,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:02:35,287 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:02:35,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:02:35,311 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,311 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:02:35,326 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,326 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:02:35,339 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,339 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:02:35,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:02:35,367 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,367 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:02:35,367 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:02:35,367 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:02:35,367 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:02:35,377 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,377 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:02:35,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:02:35,509 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,509 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:02:35,517 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,517 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:02:35,524 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,524 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:02:35,525 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:02:35,525 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:02:35,525 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:02:35,534 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,534 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:02:35,541 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,541 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:02:35,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:02:35,563 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,563 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:02:35,572 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,572 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:02:35,572 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:02:35,572 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:02:35,572 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:02:35,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:02:35,587 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,588 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:02:35,599 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,599 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:02:35,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:02:35,618 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,618 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:02:35,618 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:02:35,618 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:02:35,618 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:02:35,626 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,626 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:02:35,637 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,637 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:02:35,649 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,649 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:02:35,658 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,658 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:02:35,667 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,668 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:02:35,668 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:02:35,668 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:02:35,668 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:02:35,677 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,677 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:02:35,687 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,687 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:02:35,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:02:35,747 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:02:35,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:02:35,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:02:35,755 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:02:35,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:02:35,764 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,764 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:02:35,771 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,771 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:02:35,781 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,781 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:02:35,796 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,797 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:02:35,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:02:35,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:02:35,882 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:02:35,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:02:35,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:02:35,944 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,944 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:02:35,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:02:35,964 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,964 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:02:35,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:02:35,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:02:35,972 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:02:35,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:02:35,980 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,981 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:02:35,989 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,990 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:02:35,998 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:35,998 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:02:36,006 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,006 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:02:36,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:02:36,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:02:36,014 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:02:36,015 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:02:36,015 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 11:02:36,015 - __main__ - INFO - Started metrics monitoring
2025-04-06 11:02:36,022 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,022 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:02:36,030 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,030 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:02:36,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:02:36,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:02:36,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:02:36,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:02:36,053 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:02:36,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:02:36,063 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,063 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:02:36,071 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:02:36,081 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,081 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:02:36,089 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,089 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:02:36,099 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,099 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:02:36,099 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:02:36,099 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:02:36,099 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:02:36,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:02:36,117 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,117 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:02:36,126 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,126 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:02:36,133 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,134 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:02:36,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:02:36,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:02:36,141 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:02:36,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:02:36,151 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,151 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:02:36,158 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,158 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:02:36,162 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:02:36,168 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,168 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:02:36,176 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,176 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:02:36,186 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,186 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:02:36,186 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:02:36,187 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:02:36,187 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:02:36,195 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,195 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:02:36,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:02:36,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:02:36,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:02:36,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:02:36,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:02:36,259 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:02:36,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:02:36,275 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,275 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:02:36,293 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:02:36,316 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,316 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:02:36,324 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,324 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:02:36,342 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,342 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:02:36,342 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:02:36,342 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:02:36,342 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:02:36,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:02:36,589 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,589 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:02:36,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:02:36,678 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:02:36,686 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,686 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:02:36,686 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:02:36,686 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:02:36,686 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:02:36,694 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,694 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:02:36,773 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,774 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:02:36,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:02:36,806 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:02:36,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:02:36,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:02:36,824 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:02:36,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:02:36,838 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,838 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:02:36,851 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,851 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:02:36,861 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,861 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:02:36,876 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,876 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:02:36,887 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,887 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:02:36,887 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:02:36,888 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:02:36,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:02:36,899 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,899 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:02:36,907 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:02:36,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:02:36,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:02:36,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:02:36,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:02:36,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:02:36,932 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:02:36,932 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:03:37,137 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:03:37,160 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,160 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:03:37,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:03:37,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:03:37,199 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,199 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:03:37,207 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,208 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:03:37,208 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:03:37,208 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:03:37,208 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:03:37,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:03:37,225 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,225 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:03:37,233 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,233 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:03:37,240 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,240 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:03:37,248 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,248 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:03:37,248 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:03:37,248 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:03:37,248 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:03:37,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,257 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:03:37,279 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,279 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:03:37,286 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,286 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:03:37,292 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,292 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:03:37,300 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,301 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:03:37,301 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:03:37,301 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:03:37,301 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:03:37,313 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,313 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:03:37,321 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,321 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:03:37,328 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,328 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:03:37,338 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,338 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:03:37,344 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,344 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:03:37,344 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:03:37,344 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:03:37,344 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:03:37,354 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,354 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:03:37,360 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,361 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:03:37,372 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,372 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:03:37,380 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,380 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:03:37,388 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,388 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:03:37,388 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:03:37,388 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:03:37,388 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:03:37,456 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,456 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:03:37,466 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,466 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:03:37,474 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,474 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:03:37,489 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,490 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:03:37,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:03:37,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:03:37,500 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:03:37,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:03:37,508 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,508 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:03:37,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:03:37,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:03:37,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:03:37,538 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:03:37,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:03:37,539 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:03:37,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:03:37,546 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,546 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:03:37,553 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,553 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:03:37,559 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,559 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:03:37,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:03:37,573 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,573 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:03:37,573 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:03:37,574 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:03:37,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:03:37,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:03:37,588 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,588 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:03:37,595 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,595 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:03:37,602 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,602 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:03:37,608 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,609 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:03:37,609 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:03:37,609 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:03:37,609 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:03:37,616 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,616 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:03:37,623 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,623 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:03:37,631 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,631 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:03:37,637 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,637 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:03:37,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:03:37,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:03:37,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:03:37,644 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:03:37,644 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:04:37,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:04:37,877 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,877 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:04:37,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:04:37,896 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,897 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:04:37,905 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,905 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:04:37,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:04:37,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:04:37,915 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:04:37,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:04:37,922 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,922 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:04:37,932 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,932 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:04:37,938 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,942 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:04:37,950 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,951 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:04:37,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:04:37,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:04:37,959 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:04:37,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:04:37,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:04:37,980 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,980 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:04:37,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:37,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:04:38,001 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,001 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:04:38,011 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,011 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:04:38,011 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:04:38,011 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:04:38,011 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:04:38,021 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,021 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:04:38,033 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,034 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:04:38,042 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,042 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:04:38,050 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,050 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:04:38,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,058 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:04:38,058 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:04:38,058 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:04:38,058 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:04:38,068 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,068 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:04:38,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,077 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:04:38,085 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,085 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:04:38,094 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,094 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:04:38,104 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,105 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:04:38,105 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:04:38,105 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:04:38,105 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:04:38,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:04:38,123 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,123 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:04:38,132 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,132 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:04:38,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:04:38,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:04:38,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:04:38,157 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:04:38,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:04:38,167 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,167 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:04:38,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:04:38,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:04:38,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:04:38,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:04:38,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:04:38,217 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:04:38,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:04:38,230 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,230 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:04:38,251 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,251 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:04:38,273 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,274 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:04:38,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:04:38,289 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,289 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:04:38,290 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:04:38,290 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:04:38,290 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:04:38,297 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,297 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:04:38,304 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,304 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:04:38,311 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,311 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:04:38,318 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,318 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:04:38,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:04:38,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:04:38,325 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:04:38,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:04:38,332 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,332 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:04:38,340 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,340 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:04:38,346 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,346 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:04:38,353 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,353 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:04:38,360 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:04:38,360 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:04:38,360 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:04:38,360 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:04:38,360 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:05:38,529 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:05:38,538 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,538 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:05:38,544 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,544 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:05:38,552 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,552 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:05:38,560 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,560 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:05:38,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:05:38,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:05:38,568 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:05:38,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:05:38,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,575 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:05:38,581 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,581 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:05:38,588 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,588 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:05:38,594 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,594 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:05:38,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:05:38,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:05:38,601 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:05:38,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:05:38,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:05:38,613 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,613 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:05:38,620 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,620 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:05:38,626 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,626 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:05:38,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:05:38,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:05:38,632 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:05:38,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:05:38,638 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,638 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:05:38,643 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,643 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:05:38,649 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,649 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:05:38,656 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,656 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:05:38,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:05:38,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:05:38,662 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:05:38,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:05:38,670 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:05:38,677 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,678 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:05:38,684 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,684 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:05:38,690 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,690 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:05:38,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:05:38,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:05:38,696 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:05:38,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:05:38,703 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,703 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:05:38,711 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,711 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:05:38,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:05:38,723 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,723 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:05:38,729 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,730 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:05:38,730 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:05:38,730 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:05:38,730 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:05:38,736 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,737 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:05:38,743 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,743 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:05:38,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,750 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:05:38,756 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,756 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:05:38,762 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,762 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:05:38,762 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:05:38,762 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:05:38,762 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:05:38,769 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,769 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:05:38,775 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,775 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:05:38,781 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,781 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:05:38,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:05:38,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:05:38,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:05:38,795 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:05:38,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:05:38,802 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,802 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:05:38,808 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,808 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:05:38,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:05:38,822 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,822 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:05:38,828 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,828 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:05:38,828 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:05:38,828 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:05:38,828 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:05:38,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:05:38,841 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,841 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:05:38,848 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,848 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:05:38,855 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,855 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:05:38,861 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:05:38,861 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:05:38,861 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:05:38,861 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:05:38,861 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:06:39,056 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:06:39,067 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,067 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:06:39,073 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,073 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:06:39,079 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,079 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:06:39,085 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,085 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:06:39,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:06:39,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:06:39,091 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:06:39,092 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:06:39,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:06:39,103 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,103 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:06:39,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:06:39,116 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,116 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:06:39,122 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,122 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:06:39,122 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:06:39,122 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:06:39,122 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:06:39,128 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,128 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:06:39,135 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,135 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:06:39,140 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,140 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:06:39,147 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,147 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:06:39,153 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,153 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:06:39,153 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:06:39,153 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:06:39,153 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:06:39,159 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,160 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:06:39,165 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,166 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:06:39,172 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,172 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:06:39,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:06:39,184 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,184 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:06:39,184 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:06:39,184 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:06:39,184 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:06:39,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:06:39,196 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,196 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:06:39,202 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,202 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:06:39,208 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,209 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:06:39,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:06:39,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:06:39,215 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:06:39,215 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:06:39,225 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,225 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:06:39,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:06:39,237 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,237 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:06:39,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:06:39,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:06:39,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:06:39,249 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:06:39,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:06:39,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:06:39,261 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,261 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:06:39,268 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,268 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:06:39,274 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,274 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:06:39,279 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,280 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:06:39,280 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:06:39,280 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:06:39,280 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:06:39,286 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:06:39,292 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,292 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:06:39,298 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,298 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:06:39,304 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,305 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:06:39,310 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,310 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:06:39,310 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:06:39,310 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:06:39,311 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:06:39,316 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,317 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:06:39,324 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,324 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:06:39,330 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,330 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:06:39,337 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,337 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:06:39,343 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,343 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:06:39,343 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:06:39,343 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:06:39,343 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:06:39,349 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,349 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:06:39,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:06:39,362 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,362 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:06:39,368 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,368 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:06:39,374 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:06:39,374 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:06:39,374 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:06:39,374 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:06:39,374 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:07:39,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:07:39,584 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,585 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:07:39,592 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,592 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:07:39,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:07:39,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:07:39,614 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,614 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:07:39,614 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 488.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:07:39,614 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:07:39,615 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:07:39,674 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,676 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:07:39,707 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,707 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:07:39,713 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,713 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:07:39,720 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,720 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:07:39,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:07:39,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 388.0, 'request_rate': 18.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:07:39,727 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:07:39,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:07:39,733 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,733 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:07:39,740 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,740 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:07:39,746 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,746 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:07:39,753 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,753 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:07:39,759 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,759 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:07:39,759 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 231.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:07:39,759 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:07:39,759 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:07:39,765 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,765 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:07:39,772 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,772 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:07:39,778 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,779 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:07:39,785 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,785 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:07:39,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:07:39,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 357.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:07:39,791 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:07:39,792 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:07:39,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:07:39,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:07:39,820 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,820 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:07:39,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:07:39,832 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,832 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:07:39,832 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 203.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:07:39,832 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:07:39,832 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:07:39,838 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,838 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:07:39,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:07:39,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,851 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:07:39,857 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,857 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:07:39,863 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,863 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:07:39,863 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:07:39,863 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 11:07:39,863 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:07:39,870 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,870 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:07:39,875 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,876 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:07:39,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:07:39,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:07:39,894 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:07:39,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 224.0, 'request_rate': 14.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:07:39,895 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:07:39,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:07:39,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,902 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:07:39,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:07:39,914 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,914 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:07:39,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:07:39,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:07:39,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 278.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:07:39,927 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:07:39,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:07:39,933 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,933 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:07:39,939 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,939 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:07:39,945 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,945 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:07:39,951 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,952 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:07:39,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:07:39,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.33999999999999997, 'memory_usage': 454.0, 'request_rate': 24.0, 'error_rate': 0.014, 'latency_p95': 0.24000000000000002}
2025-04-06 11:07:39,957 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:07:39,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:07:39,963 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,963 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:07:39,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:07:39,975 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,975 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:07:39,982 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,982 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:07:39,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:39,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:07:39,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 331.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 11:07:39,988 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:07:39,988 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:07:46,187 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:07:46,239 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpha2f2olj/k8s-resources.yaml
2025-04-06 11:07:46,246 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:07:46,246 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:07:46,246 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:07:46,246 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:07:46,246 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 11:07:46,258 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 11:07:46,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:07:46,266 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,266 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:07:46,273 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,273 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:07:46,280 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,280 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:07:46,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:07:46,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:07:46,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 487.0, 'request_rate': 17.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:07:46,294 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:07:46,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:07:46,302 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,302 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:07:46,310 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,311 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:07:46,348 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,348 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:07:46,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,356 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:07:46,362 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,362 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:07:46,362 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 350.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:07:46,362 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to healthy
2025-04-06 11:07:46,362 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:07:46,370 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,370 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:07:46,377 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,377 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:07:46,383 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,383 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:07:46,391 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,391 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:07:46,398 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,399 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:07:46,399 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 223.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:07:46,399 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:07:46,399 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:07:46,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:07:46,413 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,413 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:07:46,420 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,420 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:07:46,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:07:46,433 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,434 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:07:46,434 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 362.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:07:46,434 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:07:46,434 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:07:46,440 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,440 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:07:46,446 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,446 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:07:46,453 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,453 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:07:46,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:07:46,466 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,466 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:07:46,467 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 436.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:07:46,467 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:07:46,467 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:07:46,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:07:46,481 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,481 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:07:46,488 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,488 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:07:46,494 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,494 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:07:46,501 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,501 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:07:46,501 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 459.0, 'request_rate': 29.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 11:07:46,501 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:07:46,501 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:07:46,507 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,507 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:07:46,513 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,514 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:07:46,520 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,520 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:07:46,526 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,526 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:07:46,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:07:46,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 356.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:07:46,532 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:07:46,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:07:46,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:07:46,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:07:46,553 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,553 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:07:46,558 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,558 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:07:46,565 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,565 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:07:46,565 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 470.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:07:46,565 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to healthy
2025-04-06 11:07:46,565 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:07:46,571 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,575 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:07:46,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:07:46,587 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,587 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:07:46,593 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,593 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:07:46,599 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,599 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:07:46,599 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 238.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:07:46,599 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:07:46,599 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:07:46,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:07:46,612 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,612 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:07:46,619 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,619 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:07:46,624 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,625 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:07:46,631 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,631 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:07:46,631 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 316.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:07:46,631 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:07:46,631 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:07:46,631 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 11:07:46,631 - __main__ - INFO - Started metrics monitoring
2025-04-06 11:07:46,638 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,639 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:07:46,645 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,645 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:07:46,651 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,651 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:07:46,657 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,658 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:07:46,664 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,664 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:07:46,664 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 487.0, 'request_rate': 17.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:07:46,664 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:07:46,664 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:07:46,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:07:46,677 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,677 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:07:46,683 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,683 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:07:46,690 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,690 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:07:46,697 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,697 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:07:46,697 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 350.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:07:46,697 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to healthy
2025-04-06 11:07:46,697 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:07:46,705 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,705 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:07:46,711 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,711 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:07:46,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:07:46,724 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,725 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:07:46,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:07:46,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 223.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:07:46,731 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:07:46,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:07:46,739 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,739 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:07:46,744 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,744 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:07:46,752 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,752 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:07:46,758 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,759 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:07:46,767 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,768 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:07:46,768 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 362.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:07:46,768 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:07:46,768 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:07:46,774 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,774 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:07:46,782 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,782 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:07:46,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,792 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:07:46,799 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,799 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:07:46,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:07:46,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 436.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:07:46,807 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:07:46,807 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:07:46,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:07:46,823 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:07:46,831 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,831 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:07:46,839 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,839 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:07:46,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:07:46,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 459.0, 'request_rate': 29.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 11:07:46,846 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:07:46,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:07:46,854 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,854 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:07:46,860 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,860 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:07:46,865 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,866 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:07:46,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:07:46,879 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,879 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:07:46,879 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 356.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:07:46,879 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:07:46,879 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:07:46,885 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,885 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:07:46,891 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,891 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:07:46,897 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,897 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:07:46,902 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:07:46,907 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:07:46,914 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:07:46,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 470.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:07:46,915 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to healthy
2025-04-06 11:07:46,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:07:46,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:07:46,929 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,929 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:07:46,936 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,937 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:07:46,942 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,942 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:07:46,949 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,949 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:07:46,949 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 238.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:07:46,949 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:07:46,949 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:07:46,956 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,956 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:07:46,962 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,962 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:07:46,969 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,969 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:07:46,975 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,975 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:07:46,982 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:07:46,982 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:07:46,982 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 316.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:07:46,982 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:07:46,982 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:07:53,080 - src.metrics.metrics_integration.MetricsIntegration - WARNING - Service aegis-demo not found in graph
2025-04-06 11:07:53,086 - src.metrics.metrics_integration.MetricsIntegration - WARNING - Service aegis-demo not found in graph
2025-04-06 11:07:53,089 - src.metrics.metrics_integration.MetricsIntegration - WARNING - Service aegis-demo not found in graph
2025-04-06 11:07:53,090 - src.metrics.metrics_integration.MetricsIntegration - WARNING - Service aegis-demo not found in graph
2025-04-06 11:08:47,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:08:47,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:08:47,222 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,223 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:08:47,233 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,233 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:08:47,244 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,245 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:08:47,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:08:47,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 487.0, 'request_rate': 17.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:08:47,256 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:08:47,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:08:47,269 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,269 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:08:47,281 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:08:47,293 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:08:47,305 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,305 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:08:47,320 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,320 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:08:47,321 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 350.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:08:47,321 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to healthy
2025-04-06 11:08:47,321 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:08:47,329 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,330 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:08:47,337 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,337 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:08:47,344 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,344 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:08:47,350 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,350 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:08:47,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:08:47,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 223.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:08:47,357 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:08:47,358 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:08:47,364 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,364 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:08:47,371 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,371 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:08:47,377 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,377 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:08:47,384 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,384 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:08:47,391 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,391 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:08:47,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 362.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:08:47,392 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:08:47,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:08:47,399 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,399 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:08:47,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:08:47,414 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,414 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:08:47,422 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,422 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:08:47,429 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,429 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:08:47,430 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 436.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:08:47,430 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:08:47,430 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:08:47,437 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,437 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:08:47,444 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,444 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:08:47,457 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,458 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:08:47,465 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,465 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:08:47,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,474 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:08:47,474 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 459.0, 'request_rate': 29.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 11:08:47,474 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:08:47,474 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:08:47,484 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,484 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:08:47,497 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,497 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:08:47,505 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,505 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:08:47,515 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:08:47,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:08:47,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 356.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:08:47,523 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:08:47,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:08:47,534 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,534 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:08:47,542 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,542 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:08:47,549 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,549 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:08:47,558 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,558 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:08:47,566 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:08:47,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 470.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:08:47,567 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to healthy
2025-04-06 11:08:47,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:08:47,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:08:47,582 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,582 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:08:47,590 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,591 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:08:47,598 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,598 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:08:47,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:08:47,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 238.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:08:47,606 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:08:47,606 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:08:47,613 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,614 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:08:47,625 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,625 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:08:47,635 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,635 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:08:47,643 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,643 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:08:47,652 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:08:47,653 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:08:47,653 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 316.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:08:47,653 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:08:47,653 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:09:47,845 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:09:47,875 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,876 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:09:47,890 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,890 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:09:47,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:09:47,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:09:47,925 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,925 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:09:47,926 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 487.0, 'request_rate': 17.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:09:47,926 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:09:47,926 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:09:47,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:09:47,948 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,948 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:09:47,955 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,955 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:09:47,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:09:47,967 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,967 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:09:47,967 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 350.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:09:47,967 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to healthy
2025-04-06 11:09:47,968 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:09:47,974 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,974 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:09:47,981 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,981 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:09:47,987 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:09:47,995 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:47,996 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:09:48,001 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,001 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:09:48,002 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 223.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:09:48,002 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:09:48,002 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:09:48,007 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,007 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:09:48,015 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,015 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:09:48,021 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,021 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:09:48,026 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,026 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:09:48,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:09:48,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 362.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:09:48,037 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:09:48,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:09:48,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:09:48,050 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,050 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:09:48,056 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:09:48,064 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,064 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:09:48,071 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:09:48,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 436.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:09:48,072 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:09:48,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:09:48,078 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,079 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:09:48,088 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,088 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:09:48,095 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,095 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:09:48,104 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,104 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:09:48,111 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,111 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:09:48,111 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 459.0, 'request_rate': 29.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 11:09:48,111 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:09:48,111 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:09:48,117 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,117 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:09:48,125 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,125 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:09:48,131 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,131 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:09:48,136 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,136 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:09:48,145 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,145 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:09:48,145 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 356.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:09:48,145 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:09:48,145 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:09:48,151 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,152 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:09:48,161 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,161 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:09:48,167 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,167 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:09:48,174 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,174 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:09:48,180 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,180 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:09:48,180 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 470.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:09:48,180 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to healthy
2025-04-06 11:09:48,180 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:09:48,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:09:48,200 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,200 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:09:48,207 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,207 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:09:48,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:09:48,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:09:48,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 238.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:09:48,224 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:09:48,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:09:48,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:09:48,237 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,237 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:09:48,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:09:48,251 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,251 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:09:48,257 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:09:48,257 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:09:48,257 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 316.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:09:48,257 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:09:48,257 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:10:48,457 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:10:48,472 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,472 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:10:48,487 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,487 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:10:48,499 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,499 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:10:48,508 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,508 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:10:48,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:10:48,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 487.0, 'request_rate': 17.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:10:48,516 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 11:10:48,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:10:48,525 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,525 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:10:48,537 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,537 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:10:48,543 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,543 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:10:48,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:10:48,559 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,559 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:10:48,559 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 350.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:10:48,559 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to healthy
2025-04-06 11:10:48,559 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:10:48,566 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,566 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:10:48,572 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,572 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:10:48,578 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,578 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:10:48,584 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,584 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:10:48,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:10:48,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 223.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:10:48,600 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:10:48,600 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:10:48,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,607 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:10:48,614 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,614 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:10:48,620 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,620 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:10:48,627 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,627 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:10:48,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:10:48,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 362.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:10:48,633 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:10:48,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:10:48,641 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,641 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:10:48,646 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,646 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:10:48,652 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,653 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:10:48,660 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,660 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:10:48,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:10:48,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 436.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:10:48,667 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:10:48,667 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:10:48,673 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,674 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:10:48,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:10:48,685 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,686 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:10:48,692 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,692 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:10:48,698 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,699 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:10:48,699 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 459.0, 'request_rate': 29.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 11:10:48,699 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:10:48,699 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:10:48,706 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,706 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:10:48,712 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,712 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:10:48,717 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:10:48,724 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,724 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:10:48,730 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:10:48,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 356.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:10:48,731 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:10:48,731 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:10:48,738 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,738 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:10:48,744 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,744 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:10:48,750 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,750 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:10:48,756 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,757 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:10:48,762 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,762 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:10:48,763 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 470.0, 'request_rate': 20.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:10:48,763 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to healthy
2025-04-06 11:10:48,763 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:10:48,769 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,769 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:10:48,775 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,775 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:10:48,784 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,784 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:10:48,790 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:10:48,796 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,796 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:10:48,796 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.38, 'memory_usage': 238.0, 'request_rate': 28.0, 'error_rate': 0.018000000000000002, 'latency_p95': 0.28}
2025-04-06 11:10:48,796 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:10:48,797 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:10:48,803 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,803 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:10:48,809 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,809 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:10:48,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:10:48,823 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,823 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:10:48,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:10:48,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:10:48,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 316.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:10:48,829 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 11:10:48,829 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:11:25,472 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:11:25,527 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpro4qqsvo/k8s-resources.yaml
2025-04-06 11:11:25,534 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:11:25,534 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:11:25,535 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:11:25,535 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:11:25,535 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 11:11:25,547 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 11:11:25,547 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:11:25,554 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,554 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:11:25,562 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,562 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:11:25,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,569 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:11:25,576 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,576 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:11:25,628 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,628 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:11:25,628 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:11:25,628 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:11:25,628 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:11:25,639 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,639 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:11:25,648 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,648 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:11:25,658 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,658 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:11:25,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:11:25,678 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:11:25,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:11:25,679 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:11:25,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:11:25,687 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,687 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:11:25,694 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,694 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:11:25,701 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,701 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:11:25,708 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,708 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:11:25,715 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,715 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:11:25,715 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:11:25,715 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:11:25,715 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:11:25,722 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,723 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:11:25,729 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,729 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:11:25,735 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,735 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:11:25,742 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,742 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:11:25,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:11:25,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:11:25,748 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:11:25,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:11:25,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:11:25,761 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,761 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:11:25,768 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,768 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:11:25,775 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,775 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:11:25,785 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,785 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:11:25,785 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:11:25,785 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:11:25,785 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:11:25,792 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,792 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:11:25,798 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,798 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:11:25,805 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,805 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:11:25,811 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,811 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:11:25,817 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,817 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:11:25,817 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:11:25,817 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:11:25,817 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:11:25,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,824 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:11:25,830 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,830 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:11:25,837 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,837 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:11:25,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:11:25,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:11:25,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:11:25,850 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:11:25,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:11:25,857 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,857 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:11:25,863 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,863 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:11:25,870 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,870 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:11:25,876 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,876 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:11:25,883 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,883 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:11:25,883 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:11:25,883 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:11:25,883 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:11:25,889 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,889 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:11:25,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:11:25,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:11:25,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:11:25,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:11:25,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:11:25,915 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:11:25,915 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:11:25,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:11:25,928 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,928 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:11:25,933 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,933 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:11:25,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:11:25,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:11:25,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:11:25,946 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:11:25,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:11:25,946 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 11:11:25,947 - __main__ - INFO - Started metrics monitoring
2025-04-06 11:11:25,952 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,952 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:11:25,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:11:25,965 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,965 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:11:25,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:11:25,977 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,977 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:11:25,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:11:25,978 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:11:25,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:11:25,984 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,984 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:11:25,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:11:25,997 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:25,997 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:11:26,004 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,004 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:11:26,010 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,010 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:11:26,010 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:11:26,010 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:11:26,010 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:11:26,016 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,016 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:11:26,023 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,023 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:11:26,029 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,029 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:11:26,037 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,038 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:11:26,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:11:26,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:11:26,044 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:11:26,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:11:26,050 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,050 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:11:26,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:11:26,063 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,063 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:11:26,070 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,070 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:11:26,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:11:26,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:11:26,076 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:11:26,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:11:26,082 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,082 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:11:26,089 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:11:26,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:11:26,101 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,101 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:11:26,108 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,108 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:11:26,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:11:26,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:11:26,115 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:11:26,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:11:26,122 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,122 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:11:26,128 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,128 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:11:26,134 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,134 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:11:26,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:11:26,148 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,148 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:11:26,148 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:11:26,148 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:11:26,148 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:11:26,155 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,156 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:11:26,162 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,162 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:11:26,169 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,170 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:11:26,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:11:26,185 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,185 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:11:26,185 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:11:26,185 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:11:26,185 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:11:26,192 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,192 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:11:26,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:11:26,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:11:26,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:11:26,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:11:26,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:11:26,244 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:11:26,244 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:11:26,281 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,281 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:11:26,346 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,346 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:11:26,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:11:26,368 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,368 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:11:26,381 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,381 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:11:26,381 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:11:26,381 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:11:26,381 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:11:26,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:11:26,400 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,400 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:11:26,409 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,409 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:11:26,417 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,417 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:11:26,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:11:26,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:11:26,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:11:26,426 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:11:26,426 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:12:26,622 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:12:26,636 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,637 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:12:26,646 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,647 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:12:26,655 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,655 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:12:26,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:12:26,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:12:26,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:12:26,671 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:12:26,671 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:12:26,680 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,680 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:12:26,688 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,688 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:12:26,696 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,697 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:12:26,704 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,704 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:12:26,711 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,711 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:12:26,712 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:12:26,712 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:12:26,712 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:12:26,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,719 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:12:26,726 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:12:26,733 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,733 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:12:26,742 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,742 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:12:26,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:12:26,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:12:26,749 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:12:26,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:12:26,757 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,757 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:12:26,764 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,765 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:12:26,772 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,773 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:12:26,781 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,781 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:12:26,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:12:26,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:12:26,788 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:12:26,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:12:26,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:12:26,801 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,801 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:12:26,808 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,808 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:12:26,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:12:26,825 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:12:26,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:12:26,826 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:12:26,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:12:26,833 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,833 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:12:26,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,851 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:12:26,858 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,858 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:12:26,865 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,865 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:12:26,872 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,872 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:12:26,872 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:12:26,872 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:12:26,872 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:12:26,879 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,879 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:12:26,885 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:12:26,894 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,894 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:12:26,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:12:26,907 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,907 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:12:26,907 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:12:26,907 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:12:26,907 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:12:26,913 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,913 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:12:26,920 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,920 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:12:26,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:12:26,934 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,934 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:12:26,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:12:26,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:12:26,941 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:12:26,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:12:26,948 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,948 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:12:26,954 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,954 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:12:26,963 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,963 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:12:26,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:12:26,976 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,976 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:12:26,976 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:12:26,976 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:12:26,977 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:12:26,983 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,983 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:12:26,990 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,990 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:12:26,999 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:26,999 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:12:27,006 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:27,006 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:12:27,012 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:12:27,012 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:12:27,012 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:12:27,012 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:12:27,012 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:13:27,213 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:13:27,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:13:27,232 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,232 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:13:27,238 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,238 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:13:27,245 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,245 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:13:27,252 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,252 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:13:27,252 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:13:27,252 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:13:27,253 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:13:27,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,259 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:13:27,264 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,265 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:13:27,271 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,271 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:13:27,276 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,277 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:13:27,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:13:27,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:13:27,282 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:13:27,282 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:13:27,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:13:27,293 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,293 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:13:27,300 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,300 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:13:27,307 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,307 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:13:27,315 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,315 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:13:27,315 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:13:27,315 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:13:27,315 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:13:27,321 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,321 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:13:27,332 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,333 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:13:27,341 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,341 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:13:27,349 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,349 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:13:27,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:13:27,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:13:27,355 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:13:27,355 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:13:27,361 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,361 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:13:27,366 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,367 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:13:27,373 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,373 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:13:27,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:13:27,385 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,385 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:13:27,385 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:13:27,385 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:13:27,385 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:13:27,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:13:27,398 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,398 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:13:27,403 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,403 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:13:27,409 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,409 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:13:27,415 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,415 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:13:27,415 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:13:27,415 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:13:27,415 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:13:27,421 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,421 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:13:27,429 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,429 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:13:27,437 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,437 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:13:27,444 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,444 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:13:27,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:13:27,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:13:27,451 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:13:27,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:13:27,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,461 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:13:27,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:13:27,477 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,477 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:13:27,484 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,484 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:13:27,495 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,495 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:13:27,495 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:13:27,496 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:13:27,496 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:13:27,503 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,503 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:13:27,510 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,510 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:13:27,515 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,515 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:13:27,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,523 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:13:27,528 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,528 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:13:27,529 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:13:27,529 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:13:27,529 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:13:27,536 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,536 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:13:27,546 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,546 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:13:27,553 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,553 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:13:27,560 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,560 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:13:27,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:13:27,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:13:27,567 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:13:27,567 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:13:27,567 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:14:27,782 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:14:27,811 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,812 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:14:27,828 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:14:27,852 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,852 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:14:27,867 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,868 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:14:27,897 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,898 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:14:27,898 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:14:27,898 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:14:27,898 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:14:27,913 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,913 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:14:27,926 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:14:27,938 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,938 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:14:27,954 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,954 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:14:27,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:14:27,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:14:27,961 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:14:27,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:14:27,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:14:27,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:14:27,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,992 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:14:27,999 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:27,999 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:14:28,005 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,005 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:14:28,005 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:14:28,005 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:14:28,005 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:14:28,013 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,013 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:14:28,020 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,020 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:14:28,028 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,028 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:14:28,035 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,035 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:14:28,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:14:28,053 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:14:28,054 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:14:28,054 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:14:28,062 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,062 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:14:28,068 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,068 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:14:28,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,076 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:14:28,083 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,083 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:14:28,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:14:28,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:14:28,091 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:14:28,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:14:28,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:14:28,103 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,103 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:14:28,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:14:28,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,115 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:14:28,121 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,121 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:14:28,121 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:14:28,121 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:14:28,121 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:14:28,127 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,127 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:14:28,134 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,134 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:14:28,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,141 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:14:28,149 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,150 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:14:28,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:14:28,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:14:28,157 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:14:28,157 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:14:28,164 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,164 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:14:28,172 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,172 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:14:28,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:14:28,185 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,185 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:14:28,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:14:28,193 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:14:28,193 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:14:28,194 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:14:28,200 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,200 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:14:28,208 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,208 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:14:28,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,214 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:14:28,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,225 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:14:28,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:14:28,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:14:28,231 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:14:28,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:14:28,242 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,242 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:14:28,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:14:28,261 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,261 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:14:28,268 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,268 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:14:28,275 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:14:28,276 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:14:28,276 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:14:28,276 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:14:28,276 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:15:28,470 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:15:28,482 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,482 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:15:28,492 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,492 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:15:28,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,500 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:15:28,508 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,508 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:15:28,514 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,514 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:15:28,514 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:15:28,515 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:15:28,515 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:15:28,521 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,521 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:15:28,527 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,527 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:15:28,533 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,533 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:15:28,538 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,538 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:15:28,544 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:15:28,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:15:28,545 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:15:28,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:15:28,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:15:28,556 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,556 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:15:28,562 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,562 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:15:28,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:15:28,573 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:15:28,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:15:28,574 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:15:28,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:15:28,579 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,579 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:15:28,585 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,585 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:15:28,592 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,592 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:15:28,597 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,598 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:15:28,604 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,604 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:15:28,604 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:15:28,604 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:15:28,604 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:15:28,609 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,610 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:15:28,615 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,615 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:15:28,621 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,621 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:15:28,627 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,627 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:15:28,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:15:28,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:15:28,633 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:15:28,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:15:28,639 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,639 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:15:28,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:15:28,650 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,650 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:15:28,656 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,657 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:15:28,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:15:28,662 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:15:28,662 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:15:28,663 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:15:28,668 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,668 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:15:28,674 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,674 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:15:28,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,679 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:15:28,685 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,685 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:15:28,692 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,692 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:15:28,692 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:15:28,692 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:15:28,692 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:15:28,700 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,700 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:15:28,708 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,708 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:15:28,738 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,738 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:15:28,744 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,744 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:15:28,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:15:28,749 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:15:28,749 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:15:28,750 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:15:28,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,755 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:15:28,760 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,760 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:15:28,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,788 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:15:28,794 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,795 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:15:28,831 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,831 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:15:28,831 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:15:28,831 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:15:28,831 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:15:28,838 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,838 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:15:28,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,845 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:15:28,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,850 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:15:28,856 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,856 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:15:28,861 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:15:28,862 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:15:28,862 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:15:28,862 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:15:28,862 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:16:29,047 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:16:29,061 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,062 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:16:29,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:16:29,083 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,083 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:16:29,092 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,092 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:16:29,102 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,102 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:16:29,102 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:16:29,102 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:16:29,102 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:16:29,112 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,112 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:16:29,120 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,120 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:16:29,128 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,128 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:16:29,135 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,135 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:16:29,142 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,142 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:16:29,142 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:16:29,142 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:16:29,142 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:16:29,149 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,149 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:16:29,155 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,155 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:16:29,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,164 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:16:29,170 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,170 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:16:29,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:16:29,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:16:29,178 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:16:29,178 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:16:29,183 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,183 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:16:29,192 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,192 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:16:29,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:16:29,205 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,205 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:16:29,216 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,216 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:16:29,216 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:16:29,217 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:16:29,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:16:29,226 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,226 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:16:29,234 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,234 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:16:29,242 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,242 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:16:29,248 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,248 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:16:29,255 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,255 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:16:29,255 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:16:29,255 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:16:29,255 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:16:29,262 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,262 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:16:29,269 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,269 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:16:29,275 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,275 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:16:29,283 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,283 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:16:29,289 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,290 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:16:29,290 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:16:29,290 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:16:29,290 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:16:29,297 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,297 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:16:29,303 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,303 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:16:29,310 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,310 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:16:29,316 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,316 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:16:29,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:16:29,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:16:29,325 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:16:29,325 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:16:29,332 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,332 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:16:29,342 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,342 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:16:29,348 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,348 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:16:29,356 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:16:29,365 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,365 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:16:29,365 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:16:29,365 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:16:29,365 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:16:29,372 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,372 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:16:29,378 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:16:29,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,394 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:16:29,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:16:29,433 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,433 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:16:29,433 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:16:29,433 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:16:29,433 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:16:29,441 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,441 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:16:29,448 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,448 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:16:29,456 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,456 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:16:29,462 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,463 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:16:29,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:16:29,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:16:29,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:16:29,469 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:16:29,469 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:17:29,651 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:17:29,663 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,664 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:17:29,672 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,672 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:17:29,680 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,680 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:17:29,687 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,687 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:17:29,693 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,693 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:17:29,693 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:17:29,693 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:17:29,693 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:17:29,699 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,699 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:17:29,706 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,706 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:17:29,718 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,719 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:17:29,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,727 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:17:29,734 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,734 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:17:29,734 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:17:29,734 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:17:29,735 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:17:29,743 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,743 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:17:29,750 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,750 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:17:29,758 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,759 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:17:29,765 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,765 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:17:29,771 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,771 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:17:29,771 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:17:29,771 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:17:29,771 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:17:29,777 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,777 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:17:29,783 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,783 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:17:29,789 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,789 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:17:29,797 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,797 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:17:29,804 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,804 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:17:29,804 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:17:29,804 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:17:29,804 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:17:29,810 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,810 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:17:29,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,815 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:17:29,821 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,821 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:17:29,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:17:29,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:17:29,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:17:29,835 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:17:29,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:17:29,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,844 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:17:29,852 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,852 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:17:29,859 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,859 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:17:29,866 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,866 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:17:29,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:17:29,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:17:29,873 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:17:29,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:17:29,880 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,880 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:17:29,887 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,887 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:17:29,893 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,893 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:17:29,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,901 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:17:29,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,909 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:17:29,909 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:17:29,909 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:17:29,909 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:17:29,916 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,916 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:17:29,922 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,922 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:17:29,929 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,929 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:17:29,935 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,935 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:17:29,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:17:29,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:17:29,941 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:17:29,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:17:29,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:17:29,953 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,957 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:17:29,964 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,964 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:17:29,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,972 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:17:29,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:17:29,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:17:29,978 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:17:29,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:17:29,985 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,985 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:17:29,996 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:29,996 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:17:30,002 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:30,002 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:17:30,008 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:30,008 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:17:30,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:17:30,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:17:30,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:17:30,014 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:17:30,014 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:18:30,221 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:18:30,239 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,240 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:18:30,252 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,253 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:18:30,263 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,264 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:18:30,276 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,276 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:18:30,287 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:18:30,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:18:30,288 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:18:30,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:18:30,297 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,297 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:18:30,307 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,307 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:18:30,317 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,318 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:18:30,323 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,323 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:18:30,329 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,329 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:18:30,329 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:18:30,329 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:18:30,329 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:18:30,335 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,335 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:18:30,340 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,340 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:18:30,345 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,345 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:18:30,350 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,350 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:18:30,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:18:30,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:18:30,357 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:18:30,357 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:18:30,365 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,365 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:18:30,372 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,372 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:18:30,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:18:30,386 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,386 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:18:30,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:18:30,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:18:30,392 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:18:30,392 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:18:30,398 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,398 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:18:30,405 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:18:30,412 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,412 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:18:30,418 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,418 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:18:30,424 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,424 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:18:30,424 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:18:30,424 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:18:30,424 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:18:30,430 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,430 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:18:30,436 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,439 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:18:30,445 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,445 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:18:30,452 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,452 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:18:30,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:18:30,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:18:30,459 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:18:30,459 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:18:30,465 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,465 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:18:30,470 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,470 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:18:30,476 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,477 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:18:30,484 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,484 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:18:30,492 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,492 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:18:30,492 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:18:30,492 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:18:30,492 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:18:30,498 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,499 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:18:30,505 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,505 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:18:30,511 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,511 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:18:30,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,516 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:18:30,522 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,522 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:18:30,522 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:18:30,522 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:18:30,522 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:18:30,528 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,528 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:18:30,534 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,534 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:18:30,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:18:30,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:18:30,550 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:18:30,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:18:30,551 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:18:30,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:18:30,557 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,558 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:18:30,564 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,564 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:18:30,581 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,581 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:18:30,589 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,589 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:18:30,597 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:18:30,597 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:18:30,597 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:18:30,597 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:18:30,597 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:19:30,801 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:19:30,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:19:30,823 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,823 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:19:30,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:19:30,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:19:30,856 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,856 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:19:30,856 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:19:30,856 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:19:30,856 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:19:30,865 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,865 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:19:30,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,873 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:19:30,881 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:19:30,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:19:30,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:19:30,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:19:30,895 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:19:30,896 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:19:30,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,904 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:19:30,910 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,910 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:19:30,916 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,916 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:19:30,924 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,925 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:19:30,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:19:30,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:19:30,931 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:19:30,931 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:19:30,938 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,938 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:19:30,949 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,949 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:19:30,956 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,956 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:19:30,963 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,963 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:19:30,970 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:19:30,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:19:30,971 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:19:30,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:19:30,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,978 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:19:30,985 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,986 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:19:30,994 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:30,994 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:19:31,001 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,002 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:19:31,009 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,009 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:19:31,009 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:19:31,009 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:19:31,009 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:19:31,017 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,018 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:19:31,024 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,024 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:19:31,055 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,056 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:19:31,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,091 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:19:31,096 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:19:31,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:19:31,097 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:19:31,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:19:31,102 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,102 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:19:31,108 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,108 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:19:31,114 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,114 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:19:31,121 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,121 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:19:31,127 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,127 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:19:31,127 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:19:31,127 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:19:31,127 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:19:31,133 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,133 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:19:31,139 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,139 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:19:31,145 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,145 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:19:31,152 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,153 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:19:31,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:19:31,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:19:31,163 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:19:31,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:19:31,168 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,169 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:19:31,174 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,174 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:19:31,180 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,180 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:19:31,192 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,192 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:19:31,197 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,197 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:19:31,197 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:19:31,197 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:19:31,198 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:19:31,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:19:31,209 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,209 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:19:31,215 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,215 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:19:31,221 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,221 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:19:31,229 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:19:31,229 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:19:31,230 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:19:31,230 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:19:31,230 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:20:31,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 11:20:31,437 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,437 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 11:20:31,444 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,445 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:20:31,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 11:20:31,460 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,461 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 11:20:31,468 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 11:20:31,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 380.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:20:31,469 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to healthy
2025-04-06 11:20:31,469 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 11:20:31,477 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,477 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 11:20:31,483 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,483 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:20:31,488 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,488 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 11:20:31,494 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,494 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 11:20:31,502 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,502 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 11:20:31,502 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 317.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:20:31,502 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 11:20:31,502 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 11:20:31,512 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,512 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 11:20:31,518 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,518 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:20:31,526 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,526 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 11:20:31,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,532 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 11:20:31,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 11:20:31,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:20:31,539 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 11:20:31,539 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 11:20:31,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,545 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 11:20:31,550 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,551 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:20:31,556 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,556 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 11:20:31,562 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,562 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 11:20:31,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 11:20:31,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 212.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:20:31,568 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 11:20:31,568 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 11:20:31,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,574 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 11:20:31,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,580 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:20:31,587 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,587 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 11:20:31,594 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,594 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 11:20:31,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 11:20:31,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 377.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:20:31,601 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 11:20:31,601 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 11:20:31,608 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,608 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 11:20:31,615 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,615 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:20:31,621 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,621 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 11:20:31,627 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,627 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 11:20:31,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 11:20:31,632 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 283.0, 'request_rate': 13.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 11:20:31,632 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 11:20:31,633 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 11:20:31,638 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,638 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 11:20:31,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,644 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:20:31,651 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,651 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 11:20:31,657 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,657 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 11:20:31,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 11:20:31,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 296.0, 'request_rate': 26.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 11:20:31,666 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 11:20:31,666 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 11:20:31,676 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,676 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 11:20:31,685 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,686 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:20:31,694 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,694 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 11:20:31,702 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,702 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 11:20:31,710 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,710 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 11:20:31,710 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 237.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 11:20:31,710 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 11:20:31,710 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 11:20:31,717 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,717 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 11:20:31,723 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,724 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:20:31,732 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,732 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 11:20:31,740 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,741 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 11:20:31,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 11:20:31,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 352.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 11:20:31,748 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 11:20:31,748 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 11:20:31,754 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,754 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 11:20:31,760 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,760 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:20:31,766 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,766 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 11:20:31,772 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,772 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 11:20:31,810 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 11:20:31,810 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 11:20:31,810 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.3, 'memory_usage': 260.0, 'request_rate': 10.0, 'error_rate': 0.01, 'latency_p95': 0.2}
2025-04-06 11:20:31,810 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to healthy
2025-04-06 11:20:31,810 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 11:21:20,669 - __main__ - INFO - Server interrupted by user
2025-04-06 11:21:20,959 - src.metrics.metrics_integration.MetricsIntegration - INFO - Stopped metrics monitoring thread
2025-04-06 11:21:20,959 - __main__ - INFO - Stopped metrics monitoring
2025-04-06 11:21:20,959 - __main__ - INFO - Server stopped
2025-04-06 11:36:41,124 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:36:41,186 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmphfdqutv0/k8s-resources.yaml
2025-04-06 11:36:41,193 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:36:41,193 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:36:41,193 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:36:41,193 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:36:41,193 - __main__ - WARNING - Prometheus URL not provided, metrics collection disabled
2025-04-06 11:36:41,329 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:38:35,417 - __main__ - INFO - Server interrupted by user
2025-04-06 11:38:35,418 - __main__ - INFO - Server stopped
2025-04-06 11:38:38,550 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:38:38,606 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmp2y17yvfb/k8s-resources.yaml
2025-04-06 11:38:38,612 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:38:38,612 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:38:38,612 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:38:38,613 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:38:38,613 - __main__ - WARNING - Prometheus URL not provided, metrics collection disabled
2025-04-06 11:38:39,113 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:41:54,975 - __main__ - INFO - Server interrupted by user
2025-04-06 11:41:54,975 - __main__ - INFO - Server stopped
2025-04-06 11:41:57,085 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:41:57,142 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmp1ho7rwav/k8s-resources.yaml
2025-04-06 11:41:57,149 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:41:57,150 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:41:57,150 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:41:57,150 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:41:57,150 - __main__ - WARNING - Prometheus URL not provided, metrics collection disabled
2025-04-06 11:41:57,283 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:42:07,510 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to critical
2025-04-06 11:42:07,511 - src.web.server - INFO - Injected synthetic issue synthetic-issue-20250406114207 affecting service aegis-demo/queue-service
2025-04-06 11:42:46,839 - __main__ - INFO - Server interrupted by user
2025-04-06 11:42:46,839 - __main__ - INFO - Server stopped
2025-04-06 11:54:26,310 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 11:54:26,363 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmphvnvb_rr/k8s-resources.yaml
2025-04-06 11:54:26,370 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 11:54:26,370 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 11:54:26,370 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 11:54:26,370 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 11:54:26,370 - __main__ - WARNING - Prometheus URL not provided, metrics collection disabled
2025-04-06 11:54:26,500 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 11:54:37,793 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to critical
2025-04-06 11:54:37,799 - src.web.server - INFO - Injected synthetic issue synthetic-issue-20250406115437 affecting service aegis-demo/frontend
2025-04-06 11:55:37,803 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to healthy
2025-04-06 11:55:37,804 - src.web.server - INFO - Resolved synthetic issue synthetic-issue-20250406115437 affecting service aegis-demo/frontend
2025-04-06 12:17:23,691 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 12:17:23,745 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpunj8yb9q/k8s-resources.yaml
2025-04-06 12:17:23,752 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 12:17:23,752 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 12:17:23,752 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 12:17:23,752 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 12:17:23,752 - __main__ - INFO - Enabling metrics collection from Prometheus at http://localhost:9090
2025-04-06 12:17:23,783 - __main__ - INFO - Successfully connected to Prometheus
2025-04-06 12:17:23,783 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 12:17:23,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 12:17:23,797 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,797 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 12:17:23,805 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,805 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 12:17:23,812 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,812 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 12:17:23,819 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,819 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 12:17:23,819 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 453.0, 'request_rate': 23.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 12:17:23,819 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 12:17:23,819 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 12:17:23,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,826 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 12:17:23,833 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,833 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 12:17:23,840 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,840 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 12:17:23,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,846 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 12:17:23,853 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,853 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 12:17:23,853 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 397.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 12:17:23,853 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 12:17:23,853 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 12:17:23,860 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,860 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 12:17:23,867 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,867 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 12:17:23,874 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,874 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 12:17:23,881 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,881 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 12:17:23,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 12:17:23,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 249.0, 'request_rate': 19.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 12:17:23,888 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 12:17:23,888 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 12:17:23,894 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 12:17:23,902 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,902 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 12:17:23,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,908 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 12:17:23,914 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,914 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 12:17:23,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 12:17:23,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 442.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 12:17:23,921 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 12:17:23,921 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 12:17:23,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,927 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 12:17:23,934 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,934 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 12:17:23,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,940 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 12:17:23,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,946 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 12:17:23,953 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,953 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 12:17:23,953 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 246.0, 'request_rate': 16.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 12:17:23,953 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 12:17:23,953 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 12:17:23,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,959 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 12:17:23,965 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,965 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 12:17:23,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,971 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 12:17:23,977 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,977 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 12:17:23,983 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,984 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 12:17:23,984 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.35, 'memory_usage': 385.0, 'request_rate': 15.0, 'error_rate': 0.015, 'latency_p95': 0.25}
2025-04-06 12:17:23,984 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 12:17:23,984 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 12:17:23,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,991 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 12:17:23,997 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:23,999 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 12:17:24,006 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,006 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 12:17:24,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,014 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 12:17:24,023 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,023 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 12:17:24,023 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 451.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 12:17:24,023 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 12:17:24,023 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 12:17:24,031 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,031 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 12:17:24,038 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,038 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 12:17:24,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,044 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 12:17:24,051 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,051 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 12:17:24,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 12:17:24,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 453.0, 'request_rate': 23.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 12:17:24,057 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 12:17:24,057 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 12:17:24,064 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,064 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 12:17:24,071 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,071 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 12:17:24,077 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,077 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 12:17:24,083 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,083 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 12:17:24,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 12:17:24,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 437.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 12:17:24,090 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 12:17:24,090 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 12:17:24,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 12:17:24,103 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,104 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 12:17:24,109 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,110 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 12:17:24,116 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,117 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 12:17:24,123 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,123 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 12:17:24,123 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 232.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 12:17:24,123 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 12:17:24,123 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 12:17:24,123 - src.metrics.metrics_integration.MetricsIntegration - INFO - Started metrics monitoring thread
2025-04-06 12:17:24,123 - __main__ - INFO - Started metrics monitoring
2025-04-06 12:17:24,130 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,130 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 12:17:24,136 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,137 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 12:17:24,143 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,143 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 12:17:24,149 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,149 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 12:17:24,156 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,156 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 12:17:24,156 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 453.0, 'request_rate': 23.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 12:17:24,156 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 12:17:24,156 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 12:17:24,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,163 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 12:17:24,170 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,170 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 12:17:24,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,177 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 12:17:24,184 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,184 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 12:17:24,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 12:17:24,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 397.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 12:17:24,190 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 12:17:24,190 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 12:17:24,197 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,197 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 12:17:24,203 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,204 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 12:17:24,210 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,210 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 12:17:24,216 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,217 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 12:17:24,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 12:17:24,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 249.0, 'request_rate': 19.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 12:17:24,224 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 12:17:24,224 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 12:17:24,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,231 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 12:17:24,237 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,237 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 12:17:24,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,243 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 12:17:24,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,249 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 12:17:24,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 12:17:24,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 442.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 12:17:24,256 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 12:17:24,256 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 12:17:24,262 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,262 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 12:17:24,269 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,269 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 12:17:24,274 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,274 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 12:17:24,281 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,281 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 12:17:24,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 12:17:24,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 246.0, 'request_rate': 16.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 12:17:24,288 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 12:17:24,288 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 12:17:24,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,294 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 12:17:24,300 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,300 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 12:17:24,306 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,306 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 12:17:24,313 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,313 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 12:17:24,320 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,320 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 12:17:24,320 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.35, 'memory_usage': 385.0, 'request_rate': 15.0, 'error_rate': 0.015, 'latency_p95': 0.25}
2025-04-06 12:17:24,320 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 12:17:24,320 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 12:17:24,359 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,359 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 12:17:24,370 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,371 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 12:17:24,372 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 12:17:24,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,379 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 12:17:24,387 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,387 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 12:17:24,393 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,393 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 12:17:24,393 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 451.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 12:17:24,393 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 12:17:24,393 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 12:17:24,400 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,400 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 12:17:24,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,406 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 12:17:24,413 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,413 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 12:17:24,420 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,420 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 12:17:24,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 12:17:24,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 453.0, 'request_rate': 23.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 12:17:24,426 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 12:17:24,426 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 12:17:24,445 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,445 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 12:17:24,451 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,452 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 12:17:24,458 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,458 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 12:17:24,464 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,464 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 12:17:24,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 12:17:24,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 437.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 12:17:24,473 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 12:17:24,473 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 12:17:24,481 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,481 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 12:17:24,489 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,489 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 12:17:24,497 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,497 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 12:17:24,511 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,511 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 12:17:24,517 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:17:24,517 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 12:17:24,517 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 232.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 12:17:24,517 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 12:17:24,517 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 12:18:24,705 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-service-.*"}[5m]))
2025-04-06 12:18:24,729 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,729 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-service-.*"})
2025-04-06 12:18:24,746 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,746 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 12:18:24,760 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,760 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend-service"}[5m]))
2025-04-06 12:18:24,769 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,769 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend-service"}[5m])) by (le))
2025-04-06 12:18:24,776 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,777 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend-service, adding simulated metrics
2025-04-06 12:18:24,777 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 453.0, 'request_rate': 23.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 12:18:24,777 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend-service attribute health_status to warning
2025-04-06 12:18:24,777 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-service-.*"}[5m]))
2025-04-06 12:18:24,784 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,784 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-service-.*"})
2025-04-06 12:18:24,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,791 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 12:18:24,799 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,799 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache-service"}[5m]))
2025-04-06 12:18:24,806 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,806 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache-service"}[5m])) by (le))
2025-04-06 12:18:24,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache-service, adding simulated metrics
2025-04-06 12:18:24,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 397.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 12:18:24,814 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to warning
2025-04-06 12:18:24,814 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-service-.*"}[5m]))
2025-04-06 12:18:24,822 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,822 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-service-.*"})
2025-04-06 12:18:24,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,829 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 12:18:24,835 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,836 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database-service"}[5m]))
2025-04-06 12:18:24,842 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,842 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database-service"}[5m])) by (le))
2025-04-06 12:18:24,849 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,849 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database-service, adding simulated metrics
2025-04-06 12:18:24,849 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.39, 'memory_usage': 249.0, 'request_rate': 19.0, 'error_rate': 0.019, 'latency_p95': 0.29000000000000004}
2025-04-06 12:18:24,849 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database-service attribute health_status to warning
2025-04-06 12:18:24,849 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-service-.*"}[5m]))
2025-04-06 12:18:24,857 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,857 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-service-.*"})
2025-04-06 12:18:24,867 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,867 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 12:18:24,874 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,874 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend-service"}[5m]))
2025-04-06 12:18:24,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,882 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend-service"}[5m])) by (le))
2025-04-06 12:18:24,889 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,889 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend-service, adding simulated metrics
2025-04-06 12:18:24,889 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 442.0, 'request_rate': 12.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 12:18:24,889 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend-service attribute health_status to warning
2025-04-06 12:18:24,889 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-service-.*"}[5m]))
2025-04-06 12:18:24,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,895 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-service-.*"})
2025-04-06 12:18:24,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,903 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 12:18:24,909 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,909 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue-service"}[5m]))
2025-04-06 12:18:24,916 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,916 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue-service"}[5m])) by (le))
2025-04-06 12:18:24,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue-service, adding simulated metrics
2025-04-06 12:18:24,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.36, 'memory_usage': 246.0, 'request_rate': 16.0, 'error_rate': 0.016, 'latency_p95': 0.26}
2025-04-06 12:18:24,923 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue-service attribute health_status to warning
2025-04-06 12:18:24,923 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"backend-.*"}[5m]))
2025-04-06 12:18:24,929 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,929 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"backend-.*"})
2025-04-06 12:18:24,935 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,936 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 12:18:24,941 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,942 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="backend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="backend"}[5m]))
2025-04-06 12:18:24,948 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,948 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="backend"}[5m])) by (le))
2025-04-06 12:18:24,955 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,955 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for backend, adding simulated metrics
2025-04-06 12:18:24,955 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.35, 'memory_usage': 385.0, 'request_rate': 15.0, 'error_rate': 0.015, 'latency_p95': 0.25}
2025-04-06 12:18:24,955 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to warning
2025-04-06 12:18:24,955 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"cache-.*"}[5m]))
2025-04-06 12:18:24,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,961 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"cache-.*"})
2025-04-06 12:18:24,968 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,968 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 12:18:24,974 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,974 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="cache", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="cache"}[5m]))
2025-04-06 12:18:24,981 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,981 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="cache"}[5m])) by (le))
2025-04-06 12:18:24,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for cache, adding simulated metrics
2025-04-06 12:18:24,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.31, 'memory_usage': 451.0, 'request_rate': 21.0, 'error_rate': 0.011, 'latency_p95': 0.21000000000000002}
2025-04-06 12:18:24,988 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache attribute health_status to warning
2025-04-06 12:18:24,988 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"database-.*"}[5m]))
2025-04-06 12:18:24,995 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:24,995 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"database-.*"})
2025-04-06 12:18:25,003 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,004 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 12:18:25,010 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,011 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="database", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="database"}[5m]))
2025-04-06 12:18:25,018 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,018 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="database"}[5m])) by (le))
2025-04-06 12:18:25,025 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,025 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for database, adding simulated metrics
2025-04-06 12:18:25,025 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32999999999999996, 'memory_usage': 453.0, 'request_rate': 23.0, 'error_rate': 0.013000000000000001, 'latency_p95': 0.23}
2025-04-06 12:18:25,025 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to warning
2025-04-06 12:18:25,026 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"frontend-.*"}[5m]))
2025-04-06 12:18:25,032 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,032 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"frontend-.*"})
2025-04-06 12:18:25,038 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,038 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 12:18:25,045 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,045 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="frontend", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="frontend"}[5m]))
2025-04-06 12:18:25,051 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,051 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="frontend"}[5m])) by (le))
2025-04-06 12:18:25,072 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,073 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for frontend, adding simulated metrics
2025-04-06 12:18:25,073 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.37, 'memory_usage': 437.0, 'request_rate': 27.0, 'error_rate': 0.017, 'latency_p95': 0.27}
2025-04-06 12:18:25,073 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/frontend attribute health_status to warning
2025-04-06 12:18:25,073 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying CPU usage with: sum(rate(container_cpu_usage_seconds_total{namespace="aegis-demo", pod=~"queue-.*"}[5m]))
2025-04-06 12:18:25,079 - src.metrics.prometheus_collector.PrometheusCollector - INFO - CPU result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,079 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying memory usage with: sum(container_memory_usage_bytes{namespace="aegis-demo", pod=~"queue-.*"})
2025-04-06 12:18:25,087 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Memory result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,088 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying request rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 12:18:25,096 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Request rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,097 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying error rate with: sum(rate(http_requests_total{namespace="aegis-demo", service="queue", status=~"5.."}[5m])) / sum(rate(http_requests_total{namespace="aegis-demo", service="queue"}[5m]))
2025-04-06 12:18:25,106 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Error rate result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,106 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Querying latency with: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{namespace="aegis-demo", service="queue"}[5m])) by (le))
2025-04-06 12:18:25,113 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Latency result: {'status': 'success', 'data': {'resultType': 'vector', 'result': []}}
2025-04-06 12:18:25,113 - src.metrics.prometheus_collector.PrometheusCollector - INFO - No metrics found for queue, adding simulated metrics
2025-04-06 12:18:25,113 - src.metrics.prometheus_collector.PrometheusCollector - INFO - Added simulated metrics: {'cpu_usage': 0.32, 'memory_usage': 232.0, 'request_rate': 22.0, 'error_rate': 0.012, 'latency_p95': 0.22}
2025-04-06 12:18:25,113 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/queue attribute health_status to warning
2025-04-06 12:18:25,113 - src.metrics.metrics_integration.MetricsIntegration - INFO - Updated service metrics
2025-04-06 12:18:35,451 - __main__ - INFO - Server interrupted by user
2025-04-06 12:18:36,157 - src.metrics.metrics_integration.MetricsIntegration - INFO - Stopped metrics monitoring thread
2025-04-06 12:18:36,157 - __main__ - INFO - Stopped metrics monitoring
2025-04-06 12:18:36,157 - __main__ - INFO - Server stopped
2025-04-06 12:19:22,284 - __main__ - INFO - Copied microservices-demo.yaml to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpumcgo8jb/microservices-demo.yaml
2025-04-06 12:19:22,295 - __main__ - INFO - Parsed demo Kubernetes resources from YAML file
2025-04-06 12:19:22,295 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 12:19:22,295 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 12:19:22,295 - __main__ - INFO - Built service graph with 11 nodes and 13 edges
2025-04-06 12:19:22,430 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 12:23:34,018 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 12:23:34,072 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmp345kiu53/k8s-resources.yaml
2025-04-06 12:23:34,079 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 12:23:34,079 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 12:23:34,079 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 12:23:34,079 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 12:23:34,079 - __main__ - WARNING - Prometheus URL not provided, metrics collection disabled
2025-04-06 12:23:40,661 - __main__ - INFO - Server interrupted by user
2025-04-06 12:23:40,661 - __main__ - INFO - Server stopped
2025-04-06 12:24:02,686 - __main__ - INFO - Fetching services from namespace aegis-demo
2025-04-06 12:24:02,748 - __main__ - INFO - Wrote Kubernetes resources to /var/folders/6f/2l8z4_515dq8twgg1xv2nk5c0000gn/T/tmpoc_tdrh1/k8s-resources.yaml
2025-04-06 12:24:02,755 - __main__ - INFO - Parsed real Kubernetes resources from cluster
2025-04-06 12:24:02,755 - src.graph.service_graph.ServiceGraph - INFO - Inferring relationships between services...
2025-04-06 12:24:02,755 - src.graph.service_graph.ServiceGraph - INFO - Inference complete. Added relationships based on common patterns.
2025-04-06 12:24:02,755 - __main__ - INFO - Built service graph with 10 nodes and 4 edges
2025-04-06 12:24:02,755 - __main__ - WARNING - Prometheus URL not provided, metrics collection disabled
2025-04-06 12:24:03,010 - src.web.server - INFO - Starting web server on 0.0.0.0:8080
2025-04-06 14:08:34,069 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to critical
2025-04-06 14:08:34,071 - src.web.server - INFO - Injected synthetic issue synthetic-issue-20250406140834 affecting service aegis-demo/backend
2025-04-06 14:09:34,072 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/backend attribute health_status to healthy
2025-04-06 14:09:34,074 - src.web.server - INFO - Resolved synthetic issue synthetic-issue-20250406140834 affecting service aegis-demo/backend
2025-04-06 14:13:22,039 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to critical
2025-04-06 14:13:22,041 - src.web.server - INFO - Injected synthetic issue synthetic-issue-20250406141322 affecting service aegis-demo/database
2025-04-06 14:13:31,178 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to critical
2025-04-06 14:13:31,178 - src.web.server - INFO - Injected synthetic issue synthetic-issue-20250406141331 affecting service aegis-demo/cache-service
2025-04-06 14:14:22,046 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/database attribute health_status to healthy
2025-04-06 14:14:22,046 - src.web.server - INFO - Resolved synthetic issue synthetic-issue-20250406141322 affecting service aegis-demo/database
2025-04-06 14:14:31,182 - src.graph.service_graph.ServiceGraph - INFO - Updated node aegis-demo/cache-service attribute health_status to healthy
2025-04-06 14:14:31,183 - src.web.server - INFO - Resolved synthetic issue synthetic-issue-20250406141331 affecting service aegis-demo/cache-service
